"""
CuriousBrain: ëª¨ë“  ê±¸ ì•Œê³  ì‹¶ì€ AI

ğŸ¯ ì² í•™:
    ëª¨ë“  ê±¸ ì•„ëŠ” AI âŒ
    ëª¨ë“  ê±¸ ì•Œê³  ì‹¶ì€ AI â­•
    
    ëŒ€í˜• ë„ì„œê´€(LLM)ì„ í™œìš©í•˜ë©´ì„œ
    ìì‹ ë§Œì˜ ì§€ì‹ì„ ìŒ“ì•„ê°€ëŠ” êµ¬ì¡°

êµ¬ì¡°:
    1. ì§ˆë¬¸ ë°œìƒ
    2. ë‚´ ê¸°ì–µ(í•´ë§ˆ) ë¨¼ì € ê²€ìƒ‰
    3. ëª¨ë¥´ë©´ â†’ ë„ì„œê´€(ëŒ€í˜• LLM) ë°©ë¬¸
    4. ë°°ìš´ ê²ƒ â†’ í•´ë§ˆ ì €ì¥ â†’ ê°œì¸ LLM ì „ì´
    5. ì ì  ì„±ì¥ â†’ ë„ì„œê´€ ì˜ì¡´ë„ â†“

Author: GNJz (Qquarts)
Version: 1.0
"""

import os
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field

# ê²½ë¡œ ì„¤ì •
BABYHIPPO_PATH = Path(__file__).parent.parent
NANOGPT_PATH = BABYHIPPO_PATH.parent / "nanoGPT"

# ëª¨ë“ˆ ì„í¬íŠ¸ (ìƒˆ êµ¬ì¡°)
from .brain_llm import BrainLLM, HippoToLLM
from .hippo_evolution import (
    HippoEvolutionSystem,
    EVOLUTION_STAGES,
    NetworkFeature,
    NeuronModel,
    create_evolution_system,
)
from .brain_capability import (
    BrainCapabilitySchema,
    CapabilityCategory,
    create_default_schema,
)

# ëŒ€í˜• LLM API (ë„ì„œê´€)
try:
    import openai
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False

try:
    import anthropic
    HAS_ANTHROPIC = True
except ImportError:
    HAS_ANTHROPIC = False

try:
    import requests
    HAS_REQUESTS = True
except ImportError:
    HAS_REQUESTS = False


@dataclass
class LearnedKnowledge:
    """í•™ìŠµí•œ ì§€ì‹"""
    question: str
    answer: str
    source: str  # 'memory', 'library', 'personal_llm'
    confidence: float
    learned_at: float = field(default_factory=time.time)
    access_count: int = 0


class LibraryConnector:
    """
    ëŒ€í˜• ë„ì„œê´€ ì—°ê²° (ì™¸ë¶€ LLM API)
    
    ì„¸ìƒì˜ ê±°ì˜ ëª¨ë“  ì§€ì‹ì— ì ‘ê·¼
    """
    
    PROVIDERS = {
        'openai': {
            'models': ['gpt-4o', 'gpt-4-turbo', 'gpt-3.5-turbo'],
            'env_key': 'OPENAI_API_KEY',
        },
        'anthropic': {
            'models': ['claude-sonnet-4-20250514', 'claude-3-haiku-20240307'],
            'env_key': 'ANTHROPIC_API_KEY',
        },
        'local': {
            'models': ['nanoGPT'],
            'env_key': 'NANOGPT_SERVER_URL',  # ì˜ˆ: http://192.168.1.100:5000
        },
    }
    
    def __init__(self, provider: str = 'openai', model: str = None):
        self.provider = provider
        self.model = model or self._get_default_model(provider)
        self.client = None
        self._setup_client()
        
        # ì‚¬ìš© í†µê³„
        self.visit_count = 0
        self.total_tokens = 0
    
    def _get_default_model(self, provider: str) -> str:
        if provider == 'openai':
            return 'gpt-3.5-turbo'  # ì €ë ´í•œ ëª¨ë¸ ê¸°ë³¸
        elif provider == 'anthropic':
            return 'claude-3-haiku-20240307'
        elif provider == 'local':
            return 'nanoGPT'
        return 'gpt-3.5-turbo'
    
    def _setup_client(self):
        """API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •"""
        if self.provider == 'openai' and HAS_OPENAI:
            api_key = os.getenv('OPENAI_API_KEY')
            if api_key:
                self.client = openai.OpenAI(api_key=api_key)
        elif self.provider == 'anthropic' and HAS_ANTHROPIC:
            api_key = os.getenv('ANTHROPIC_API_KEY')
            if api_key:
                self.client = anthropic.Anthropic(api_key=api_key)
        elif self.provider == 'local':
            # ë¡œì»¬ nanoGPT ì„œë²„ URL
            self.server_url = os.getenv('NANOGPT_SERVER_URL', 'http://localhost:5000')
            if HAS_REQUESTS:
                self.client = 'local'  # requests ì‚¬ìš©
    
    def ask(self, question: str, context: str = "") -> Tuple[str, bool]:
        """
        ë„ì„œê´€ì— ì§ˆë¬¸
        
        Args:
            question: ì§ˆë¬¸
            context: ì¶”ê°€ ë§¥ë½
            
        Returns:
            (ë‹µë³€, ì„±ê³µì—¬ë¶€)
        """
        if not self.client:
            return "[ë„ì„œê´€ ì—°ê²° ì•ˆë¨]", False
        
        self.visit_count += 1
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = """ë‹¹ì‹ ì€ ì§€ì‹ ë„ì„œê´€ì…ë‹ˆë‹¤. 
ì§ˆë¬¸ì— ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ëª¨ë¥´ëŠ” ê²ƒì€ ëª¨ë¥¸ë‹¤ê³  ì†”ì§íˆ ë§í•´ì£¼ì„¸ìš”."""
        
        user_prompt = question
        if context:
            user_prompt = f"ë§¥ë½: {context}\n\nì§ˆë¬¸: {question}"
        
        try:
            if self.provider == 'openai':
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    max_tokens=500,
                    temperature=0.7,
                )
                answer = response.choices[0].message.content
                self.total_tokens += response.usage.total_tokens
                return answer, True
                
            elif self.provider == 'anthropic':
                response = self.client.messages.create(
                    model=self.model,
                    max_tokens=500,
                    system=system_prompt,
                    messages=[
                        {"role": "user", "content": user_prompt}
                    ]
                )
                answer = response.content[0].text
                return answer, True
            
            elif self.provider == 'local' and HAS_REQUESTS:
                # ë¡œì»¬ nanoGPT ì„œë²„ í˜¸ì¶œ
                response = requests.post(
                    f"{self.server_url}/generate",
                    json={
                        "prompt": user_prompt,
                        "max_tokens": 200,
                        "temperature": 0.8,
                    },
                    timeout=30
                )
                if response.status_code == 200:
                    result = response.json()
                    answer = result.get('new_text', result.get('generated', ''))
                    return answer, True
                else:
                    return f"[ì„œë²„ ì˜¤ë¥˜: {response.status_code}]", False
                
        except Exception as e:
            return f"[ë„ì„œê´€ ì˜¤ë¥˜: {e}]", False
        
        return "[ì§€ì›í•˜ì§€ ì•ŠëŠ” ì œê³µì]", False
    
    def get_stats(self) -> Dict:
        return {
            'provider': self.provider,
            'model': self.model,
            'connected': self.client is not None,
            'visit_count': self.visit_count,
            'total_tokens': self.total_tokens,
        }


class CuriousBrain:
    """
    í˜¸ê¸°ì‹¬ ìˆëŠ” ë‡Œ - ëª¨ë“  ê±¸ ì•Œê³  ì‹¶ì€ AI
    
    êµ¬ì¡°:
        í•´ë§ˆ (ê¸°ì–µ) + ê°œì¸ LLM + ëŒ€í˜• ë„ì„œê´€
        
    í•™ìŠµ íë¦„:
        1. ë‚´ ê¸°ì–µì—ì„œ ì°¾ê¸°
        2. ì—†ìœ¼ë©´ ë„ì„œê´€ ë°©ë¬¸
        3. ë°°ìš´ ê²ƒ ì €ì¥
        4. ìˆ˜ë©´ ì‹œ ê°œì¸ LLM ì „ì´
        5. ì ì  ì„±ì¥!
    """
    
    def __init__(self, 
                 name: str = "curious",
                 library_provider: str = 'openai',
                 library_model: str = None,
                 personal_model_path: str = None):
        """
        Args:
            name: ë‡Œ ì´ë¦„
            library_provider: ë„ì„œê´€ ì œê³µì ('openai', 'anthropic')
            library_model: ë„ì„œê´€ ëª¨ë¸
            personal_model_path: ê°œì¸ LLM ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
        """
        self.name = name
        
        # 1. í•´ë§ˆ + ê°œì¸ LLM
        model_path = personal_model_path
        if model_path is None:
            default_path = NANOGPT_PATH / "out-hippo" / "ckpt.pt"
            if default_path.exists():
                model_path = str(default_path)
        
        self.brain = BrainLLM(model_path=model_path)
        
        # 2. ëŒ€í˜• ë„ì„œê´€ ì—°ê²°
        self.library = LibraryConnector(
            provider=library_provider,
            model=library_model
        )
        
        # 3. í•™ìŠµ ê¸°ë¡
        self.knowledge_base: Dict[str, LearnedKnowledge] = {}
        
        # ğŸª v1.1: ëŒ€í™” ë§¥ë½ ê´€ë¦¬
        self.conversation_context: List[Dict] = []  # ìµœê·¼ ëŒ€í™” ê¸°ë¡
        self.max_context = 10  # ìµœê·¼ 10í„´ ê¸°ì–µ
        self.last_learning: Optional[str] = None  # ë§ˆì§€ë§‰ í•™ìŠµ ë‚´ìš©
        self.last_question: Optional[str] = None  # ë§ˆì§€ë§‰ ì§ˆë¬¸ (ì—°ì† ì§ˆë¬¸ ì²˜ë¦¬ìš©)
        
        # 4. ì„¤ì •
        # ğŸª ì €ì „ë ¥ ëª¨ë“œ: ë¼ì¦ˆë² ë¦¬íŒŒì´/ì—£ì§€ ë””ë°”ì´ìŠ¤ ìµœì í™”
        # ê¸°ë³¸ì ìœ¼ë¡œ ê°œì¸ LLM ë¹„í™œì„±í™” (ë°œì—´/ì „ë ¥ ì†Œë¹„ ìµœì†Œí™”)
        self.config = {
            'memory_threshold': 0.6,  # ì´ ì´ìƒì´ë©´ ê¸°ì–µì—ì„œ ë‹µë³€
            'learn_from_library': True,  # ë„ì„œê´€ ë‹µë³€ í•™ìŠµ ì—¬ë¶€
            'auto_consolidate': True,  # ìë™ ê³µê³ í™”
            'use_personal_llm': False,  # ğŸª ì €ì „ë ¥ ëª¨ë“œ: ê°œì¸ LLM ê¸°ë³¸ ë¹„í™œì„±í™” (ë°œì—´/ì „ë ¥ ì ˆì•½)
        }
        
        # 5. í†µê³„
        self.stats = {
            'questions_asked': 0,
            'answered_from_memory': 0,
            'answered_from_library': 0,
            'answered_from_personal_llm': 0,
            'answered_from_quick': 0,  # ğŸ’° ë¹ ë¥¸ ì‘ë‹µ (ë¹„ìš© ì ˆì•½)
        }
        
        # ğŸ¦› 6. ì§„í™” ì‹œìŠ¤í…œ ë° ë‚´ë¶€ ìƒíƒœ í”Œë˜ê·¸
        # ë¸”ë¡ì²´ì¸ì€ ì„ íƒì  ê³„ì¸µ (ê¸°ë³¸: False, ë…ë¦½í˜• ì‹œìŠ¤í…œ)
        self.evolution_system = create_evolution_system(blockchain_enabled=False)
        
        # ğŸ§© BrainCapability Schema (í™•ì¥ ê°€ëŠ¥í•œ ëŠ¥ë ¥ í”Œë˜ê·¸)
        self.capability_schema = create_default_schema()
        
        # ë‚´ë¶€ ìƒíƒœ í”Œë˜ê·¸ (ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­ ì¶”ì ) - í•˜ìœ„ í˜¸í™˜ì„±
        self.internal_flags = {
            'neuron_count': 0,  # ì‹¤ì œ ë‰´ëŸ° ìˆ˜
            'fps': 0.0,  # í˜„ì¬ FPS
            'axon_nodes': 0,  # Axon ë…¸ë“œ ìˆ˜
            'features': set(),  # êµ¬í˜„ëœ ê¸°ëŠ¥ í”Œë˜ê·¸
            'models': set(),  # ì‚¬ìš© ì¤‘ì¸ ë‰´ëŸ° ëª¨ë¸
            'stability_test_passed': False,
            'robustness_test_passed': False,
        }
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì • (BabyHippo ê¸°ë³¸)
        self._update_internal_flags()
        self._update_capability_schema()
    
    # ğŸ’° ë¹„ìš© ê´€ë¦¬: ê°„ë‹¨í•œ ì§ˆë¬¸ì€ ë„ì„œê´€(API) ì•ˆ ê°
    QUICK_RESPONSES = {
        # ì¸ì‚¬
        'ì•ˆë…•': 'ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š',
        'hi': 'Hello! ğŸ˜Š',
        'hello': 'Hi there! ğŸ˜Š',
        # ê°ì‚¬
        'ê³ ë§ˆì›Œ': 'ì²œë§Œì—ìš”! ğŸ˜Š',
        'ê°ì‚¬': 'ë³„ë§ì”€ì„ìš”! ğŸ˜Š',
        'thanks': "You're welcome! ğŸ˜Š",
        # ì‘ë³„
        'ì˜ ì': 'ì˜ ììš”! ì¢‹ì€ ê¿ˆ ê¿”ìš” ğŸ’¤',
        'ì˜ì': 'ì˜ ììš”! ğŸ’¤',
        'bye': 'Goodbye! ğŸ‘‹',
        # ì•ˆë¶€
        'ë­í•´': 'ê³µë¶€í•˜ê³  ìˆì–´ìš”! ğŸ“š',
        'ë­í•˜ê³  ìˆì–´': 'ì—´ì‹¬íˆ ë°°ìš°ê³  ìˆì–´ìš”! ğŸ§ ',
        # ê°íƒ„
        'ëŒ€ë‹¨í•´': 'í—¤í—¤, ê°ì‚¬í•´ìš”! ğŸ˜Š',
        'ì˜í–ˆì–´': 'ê³ ë§ˆì›Œìš”! ë” ì—´ì‹¬íˆ í• ê²Œìš”! ğŸ’ª',
        # í™•ì¸
        'ì•Œê² ì–´': 'ë„¤! ğŸ˜Š',
        'ê·¸ë˜': 'ë„¤ë„¤~ ğŸ˜Š',
        'ok': 'Okay! ğŸ‘',
        # í˜¸ì¹­
        'ëˆ„êµ¬ì•¼': 'ì €ëŠ” babyhippoì˜ˆìš”! ëª¨ë“  ê±¸ ì•Œê³  ì‹¶ì€ AIëë‹ˆë‹¤ ğŸ¦›',
        'ì´ë¦„ì´ ë­ì•¼': 'ì €ëŠ” babyhippoì˜ˆìš”! ğŸ¦›',
        # ğŸª v1.0: ì¶”ê°€ ì‘ë‹µ
        'ì¿ í‚¤': 'ë„¤, ì €ì˜ˆìš”! ğŸª',
        'íˆí¬': 'ë„¤, ì €ì˜ˆìš”! ğŸ¦›',
    }
    
    def think(self, question: str) -> str:
        """
        ìƒê°í•˜ê¸° (ì§ˆë¬¸ì— ë‹µí•˜ê¸°)
        
        ìˆœì„œ:
        0. ğŸª v1.0: ìì—°ì–´ í•™ìŠµ ëª…ë ¹ ìë™ ê°ì§€
        1. ê°„ë‹¨í•œ ì§ˆë¬¸ â†’ ì¦‰ì‹œ ì‘ë‹µ (ë¹„ìš© ì ˆì•½) ğŸ’°
        2. í•´ë§ˆ(ê¸°ì–µ)ì—ì„œ ê²€ìƒ‰
        3. ì—†ìœ¼ë©´ â†’ ê°œì¸ LLM ì‹œë„
        4. ê·¸ë˜ë„ ì—†ìœ¼ë©´ â†’ ë„ì„œê´€ ë°©ë¬¸
        5. ë°°ìš´ ê²ƒ ì €ì¥
        
        Args:
            question: ì§ˆë¬¸ ë˜ëŠ” í•™ìŠµ ëª…ë ¹
            
        Returns:
            ë‹µë³€
        """
        self.stats['questions_asked'] += 1
        
        # 0. ğŸª v1.2: ì§ˆë¬¸ ê°ì§€ ìµœìš°ì„  (í•™ìŠµë³´ë‹¤ ë¨¼ì €)
        # ì§ˆë¬¸ê³¼ í•™ìŠµ ëª…ë ¹ì„ ì •í™•íˆ êµ¬ë¶„
        
        question_clean = question.strip()
        
        # ğŸª v1.5: ì§ˆë¬¸ íŒ¨í„´ ê°ì§€ ê°•í™” (ìµœìš°ì„ )
        # ì§ˆë¬¸ì´ë©´ ì ˆëŒ€ í•™ìŠµìœ¼ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
        
        # 1ë‹¨ê³„: ëª…í™•í•œ ì§ˆë¬¸ ë§ˆì»¤ (ìµœìš°ì„ )
        has_question_marker = (
            '?' in question or
            question_clean.endswith('?') or
            question_clean.endswith('ìš”?') or
            question_clean.endswith('ì•¼?')
        )
        
        # 2ë‹¨ê³„: ì˜ë¬¸ì‚¬ í¬í•¨
        has_interrogative = any(word in question for word in [
            'ë­', 'ë¬´ì—‡', 'ì–´ë–»ê²Œ', 'ì–¸ì œ', 'ì–´ë””', 'ëˆ„êµ¬', 'ì™œ', 'ê¸°ì–µë‚˜', 'ê¸°ì–µí•´'
        ])
        
        # 3ë‹¨ê³„: ì§ˆë¬¸ íŒ¨í„´
        is_question_pattern = (
            question_clean in ['ë‚˜ëŠ”?', 'ë„ˆëŠ”?', 'ë‚˜ì´ëŠ”?', 'ì´ë¦„ì€?', 'ì´ë¦„ì´?', 'ë‚´ì´ë¦„ì€?', 'ë„ˆì´ë¦„ì€?', 
                              'ë‚˜ì˜ ì´ë¦„ì€?', 'ë‹¹ì‹ ì˜ ì´ë¦„ì€?', 'ìš°ë¦¬ì˜ ì´ë¦„ì€?', 'ê·¸ëŒ€ì˜ ì´ë¦„ì€?'] or
            question_clean.endswith('ëŠ”?') or
            question_clean.endswith('ì€?') or
            question_clean.endswith('ì´ê°€?') or
            question_clean.endswith('ì´ê°€?') or
            question_clean.endswith('ì˜ ì´ë¦„ì€?') or
            question_clean.endswith('ì˜ ì´ë¦„ì´?')
        )
        
        # 4ë‹¨ê³„: "ì´ë¦„" + ì§ˆë¬¸ ë§ˆì»¤
        has_name_question = (
            'ì´ë¦„' in question and 
            (has_question_marker or has_interrogative or 'ê¸°ì–µë‚˜' in question)
        )
        
        # 5ë‹¨ê³„: "ë„ˆ", "ë‹¹ì‹ ", "ì¿ í‚¤" í¬í•¨ + ì§ˆë¬¸ ë§ˆì»¤
        has_you_question = (
            ('ë„ˆ' in question or 'ë‹¹ì‹ ' in question or 'ì¿ í‚¤' in question or 'ê·¸ëŒ€' in question or 'ìš°ë¦¬' in question) and
            (has_question_marker or has_interrogative)
        )
        
        # ìµœì¢… ì§ˆë¬¸ íŒë‹¨
        is_question = (
            has_question_marker or
            has_interrogative or
            is_question_pattern or
            has_name_question or
            has_you_question
        )
        
        # ğŸª v1.2: ì§ˆë¬¸ì´ë©´ ì ˆëŒ€ í•™ìŠµìœ¼ë¡œ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
        if is_question:
            # ì§ˆë¬¸ ì²˜ë¦¬ë¡œ ë„˜ì–´ê° (ì•„ë˜ ì½”ë“œ ê³„ì†)
            pass
        else:
            # í•™ìŠµ ëª…ë ¹ íŒ¨í„´ (ëª…í™•í•œ ìê¸°ì†Œê°œë§Œ)
            learning_patterns = [
                'ë¼ê³  í•´', 'ë¼ê³  í•´ìš”', 'ë¼ê³  í•©ë‹ˆë‹¤',
            ]
            
            # ğŸª v1.2: "ë‚´ ì´ë¦„ì€ GNJz" ê°™ì€ íŒ¨í„´ì€ í•™ìŠµ ëª…ë ¹
            # í•˜ì§€ë§Œ ì§ˆë¬¸ì´ ì•„ë‹ˆê³ , ì‹¤ì œ ë‚´ìš©ì´ ìˆì–´ì•¼ í•¨
            name_intro_patterns = ['ë‚´ ì´ë¦„ì€', 'ë‚˜ëŠ”', 'ì €ëŠ”', 'ë‚´ê°€', 'ì œê°€']
            has_name_intro = any(pattern in question for pattern in name_intro_patterns)
            
            # ì‹¤ì œ ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸
            # "ë‚´ ì´ë¦„ì€ GNJz" (ë‚´ìš© ìˆìŒ) vs "ë‚´ ì´ë¦„ì€" (ë‚´ìš© ì—†ìŒ)
            has_actual_content = False
            if has_name_intro:
                for pattern in name_intro_patterns:
                    if pattern in question:
                        after_pattern = question.split(pattern, 1)[-1].strip()
                        # íŒ¨í„´ ì´í›„ì— ì‹¤ì œ ë‚´ìš©ì´ ìˆëŠ”ì§€ (ë‹¨ì–´ê°€ ìˆê³ , ì§ˆë¬¸ ë§ˆì»¤ê°€ ì•„ë‹˜)
                        if after_pattern and len(after_pattern) > 0:
                            # ì§ˆë¬¸ ë§ˆì»¤ë§Œ ìˆìœ¼ë©´ ë‚´ìš© ì—†ìŒ
                            if after_pattern not in ['?', 'ë­', 'ë¬´ì—‡', 'ë­ì•¼', 'ë¬´ì—‡ì´ì•¼', 'ê¸°ì–µë‚˜', 'ê¸°ì–µí•´']:
                                # ì‹¤ì œ ë‹¨ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸ (ìµœì†Œ 1ê¸€ì ì´ìƒ)
                                if len(after_pattern.replace(' ', '')) > 0:
                                    has_actual_content = True
                        break
            
            # í•™ìŠµ ëª…ë ¹ ê°ì§€ ì¡°ê±´:
            # 1. "ë¼ê³  í•´" íŒ¨í„´ì´ ìˆê³  ì§ˆë¬¸ì´ ì•„ë‹ˆê±°ë‚˜
            # 2. ì´ë¦„ ì†Œê°œ íŒ¨í„´ì´ ìˆê³ , ì§ˆë¬¸ì´ ì•„ë‹ˆê³ , ì‹¤ì œ ë‚´ìš©ì´ ìˆì„ ë•Œ
            is_learning_command = (
                (any(pattern in question for pattern in learning_patterns) and not is_question) or
                (has_name_intro and not is_question and has_actual_content)
            )
            
            # í•™ìŠµ ëª…ë ¹ìœ¼ë¡œ ì²˜ë¦¬
            if is_learning_command:
                # ğŸ›‘ ì¹˜ëª…ì  ì¶©ëŒ í•´ê²° #1: ì§ˆë¬¸ í•„í„°ë§ (ì´ì¤‘ ì²´í¬)
                if not self._is_question_strict(question):
                    # í•™ìŠµ ëª…ë ¹ìœ¼ë¡œ ì²˜ë¦¬
                    self.learn(question, importance=0.8)
                
                # ğŸª v1.1: ë§ˆì§€ë§‰ í•™ìŠµ ë‚´ìš© ì €ì¥ (ì˜¤ë¥˜ ìˆ˜ì •ìš©)
                self.last_learning = question
                
                # ğŸª v1.0: í•™ìŠµ í›„ ì¦‰ì‹œ í™•ì¸ ê°€ëŠ¥í•˜ë„ë¡ ì‘ë‹µ ê°œì„ 
                # ì´ë¦„ ì¶”ì¶œ ì‹œë„
                name = None
                if 'ë¼ê³  í•´' in question:
                    # "ë‚˜ëŠ” GNJzë¼ê³  í•´" â†’ "GNJz" ì¶”ì¶œ
                    parts = question.split('ë¼ê³  í•´')
                    if parts:
                        name_part = parts[0].strip()
                        # "ë‚˜ëŠ”", "ì €ëŠ”" ë“± ì œê±°
                        for prefix in ['ë‚˜ëŠ”', 'ì €ëŠ”', 'ë‚´ê°€', 'ì œê°€']:
                            if name_part.startswith(prefix):
                                name_part = name_part[len(prefix):].strip()
                        if name_part:
                            name = name_part
                elif 'ë‚´ ì´ë¦„ì€' in question:
                    # "ë‚´ ì´ë¦„ì€ GNJz" â†’ "GNJz" ì¶”ì¶œ
                    parts = question.split('ë‚´ ì´ë¦„ì€')
                    if len(parts) > 1:
                        name = parts[1].strip().replace('?', '').strip()
                
                # ğŸª v1.1: ë§¥ë½ì— ëŒ€í™” ê¸°ë¡ ì¶”ê°€
                response = f"ì•Œê² ì–´ìš”! {name if name else 'ê¸°ì–µí• ê²Œìš”'}! ğŸ˜Š"
                self._update_context(question, response, 'learning')
                
                # ì ì ˆí•œ ì‘ë‹µ ë°˜í™˜
                if name:
                    return f"ì•Œê² ì–´ìš”! {name}ì´ë¼ê³  ê¸°ì–µí• ê²Œìš”! ğŸ˜Š"
                elif 'ì´ë¦„' in question or 'ë¼ê³  í•´' in question:
                    return "ì•Œê² ì–´ìš”! ê¸°ì–µí• ê²Œìš”! ğŸ˜Š"
                elif 'ê¸°ì–µ' in question:
                    return "ë„¤, ê¸°ì–µí• ê²Œìš”! ğŸ˜Š"
                else:
                    return "í•™ìŠµ ì™„ë£Œ! ğŸ˜Š"
        
        # ğŸª v1.1: ì˜¤ë¥˜ ìˆ˜ì • ì²˜ë¦¬ ("ì•„ë‹ˆì•¼", "ê·¸ê²Œ ì•„ë‹ˆì•¼")
        correction_patterns = ['ì•„ë‹ˆì•¼', 'ê·¸ê²Œ ì•„ë‹ˆì•¼', 'í‹€ë ¸ì–´', 'ì•„ë‹ˆ', 'ìˆ˜ì •í•´']
        if any(pattern in question for pattern in correction_patterns):
            if self.last_learning:
                # ë§ˆì§€ë§‰ í•™ìŠµ ë‚´ìš© ì‚­ì œ/ìˆ˜ì •
                # (ì‹¤ì œë¡œëŠ” ê¸°ì–µì—ì„œ ì°¾ì•„ì„œ ì‚­ì œí•˜ê±°ë‚˜ ìˆ˜ì •í•´ì•¼ í•¨)
                self.last_learning = None
                return "ì•Œê² ì–´ìš”! ìˆ˜ì •í• ê²Œìš”. ë‹¤ì‹œ ì•Œë ¤ì£¼ì„¸ìš”! ğŸ˜Š"
            else:
                return "ë¬´ì—‡ì„ ìˆ˜ì •í•˜ë©´ ë ê¹Œìš”?"
        
        # ğŸª v1.1: íŠ¹ìˆ˜ ì§ˆë¬¸ ì²˜ë¦¬ (ë§¥ë½ ê¸°ë°˜)
        if question_clean == 'ë„ˆëŠ”?' or question_clean == 'ë„ˆëŠ”':
            # ì¿ í‚¤ ì´ë¦„ ë‹µë³€
            return f"ì €ëŠ” {self.name}ì´ì—ìš”! ğŸ˜Š"
        
        if 'ë‚˜ì´ëŠ”?' in question or question_clean == 'ë‚˜ì´ëŠ”?':
            # ë‚˜ì´ ì§ˆë¬¸
            return "ì €ëŠ” ì•„ì§ ë‚˜ì´ê°€ ì—†ì–´ìš”. í•˜ì§€ë§Œ ê³„ì† ë°°ìš°ê³  ìˆì–´ìš”! ğŸ˜Š"
        
        # 1. ğŸ’° ê°„ë‹¨í•œ ì§ˆë¬¸ í•„í„° (ë„ì„œê´€ ë¹„ìš© ì ˆì•½)
        question_lower = question.lower().strip()
        for pattern, response in self.QUICK_RESPONSES.items():
            if pattern in question_lower:
                self.stats['answered_from_quick'] += 1
                return response
        
        # ğŸª v1.3: ë§¥ë½ ê¸°ë°˜ ì§ˆë¬¸ ì²˜ë¦¬
        # ì´ì „ ëŒ€í™”ë¥¼ ì°¸ì¡°í•˜ì—¬ ì§ˆë¬¸ ì´í•´
        contextual_question = self._enhance_with_context(question)
        
        # 1. í•´ë§ˆì—ì„œ ê²€ìƒ‰
        # ğŸª v1.0: í‚¤ì›Œë“œ ì¶”ì¶œ ê°œì„ 
        question_keywords = self._extract_keywords(contextual_question)
        
        # ğŸª v1.0: "ë‚´ ì´ë¦„ ê¸°ì–µë‚˜?" ê°™ì€ ì§ˆë¬¸ ì²˜ë¦¬
        # "ì´ë¦„", "ê¸°ì–µë‚˜" ê°™ì€ ë¶ˆìš©ì–´ ì œê±°í•˜ê³  ì‹¤ì œ ì´ë¦„ ì°¾ê¸°
        all_memories = []  # ì´ˆê¸°í™” (ì˜¤ë¥˜ ë°©ì§€)
        
        if 'ì´ë¦„' in question or 'ê¸°ì–µë‚˜' in question:
            # ì´ë¦„ ê´€ë ¨ ì§ˆë¬¸ â†’ ëª¨ë“  ê¸°ì–µì—ì„œ ì´ë¦„ ì°¾ê¸°
            # PanoramaMemoryì—ì„œ ì´ë¦„ íŒ¨í„´ ì°¾ê¸°
            name_results = self.brain.recall("ì´ë¦„", top_n=10)
            if name_results:
                if isinstance(name_results, list):
                    all_memories.extend(name_results)
                else:
                    all_memories.append({'source': 'hippo', 'content': name_results, 'score': 0.8})
            
            # "ë¼ê³  í•´" íŒ¨í„´ìœ¼ë¡œë„ ê²€ìƒ‰
            if not all_memories:
                rago_results = self.brain.recall("ë¼ê³  í•´", top_n=10)
                if rago_results:
                    if isinstance(rago_results, list):
                        all_memories.extend(rago_results)
                    else:
                        all_memories.append({'source': 'hippo', 'content': rago_results, 'score': 0.8})
        else:
            # ì¼ë°˜ ê²€ìƒ‰
            for keyword in question_keywords:
                memories = self.brain.recall(keyword, top_n=5)
                if memories:
                    if isinstance(memories, list):
                        all_memories.extend(memories)
                    else:
                        all_memories.append({'source': 'hippo', 'content': memories, 'score': 0.8})
        
        # ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ ì •ë ¬
        seen = set()
        unique_memories = []
        for m in all_memories:
            content = str(m.get('content', ''))
            if content and content not in seen:
                seen.add(content)
                unique_memories.append(m)
        
        # ì ìˆ˜ë¡œ ì •ë ¬
        unique_memories.sort(key=lambda x: x.get('score', 0), reverse=True)
        
        # ğŸª v1.0: all_memories ë³€ìˆ˜ëª… í†µì¼ (ì˜¤ë¥˜ ë°©ì§€)
        memories = unique_memories
        
        if memories:
            # ğŸª v1.0: Panorama ìš°ì„  (ì „ì²´ ë¬¸ì¥ ì €ì¥)
            panorama_memories = [m for m in memories if m.get('source') == 'panorama']
            if panorama_memories:
                best_memory = panorama_memories[0]
                confidence = best_memory.get('score', 0.5)
                
                # PanoramaëŠ” threshold ë‚®ì¶¤ (ì „ì²´ ë¬¸ì¥ì´ë¯€ë¡œ ë” ì •í™•)
                if confidence >= self.config['memory_threshold'] * 0.5:
                    self.stats['answered_from_memory'] += 1
                    best_content = best_memory.get('content', '')
                    if best_content:
                        # ğŸ“ ì¹˜ëª…ì  ì¶©ëŒ í•´ê²° #2: ì¶œë ¥ í¬ë§·íŒ… íŒŒì´í”„ë¼ì¸ í†µê³¼
                        raw_answer = str(best_content)
                        answer = self._format_output(raw_answer, question)
                        
                        # ì§ˆë¬¸ì´ ì•„ë‹ˆê³  ì™„ì „í•œ ë¬¸ì¥ì¸ì§€ í™•ì¸
                        if not self._is_question_strict(answer) and len(answer) > 5:
                            # ì¤‘ë³µ ì œê±°
                            answer = self._clean_answer(answer, question_keywords)
                            self._record_knowledge(question, answer, 'memory', confidence)
                            return answer
            
            # HippoMemory ê²°ê³¼ ì‚¬ìš©
            best_memory = memories[0]
            confidence = best_memory.get('score', 0.5)
            
            if confidence >= self.config['memory_threshold']:
                # ì¶©ë¶„íˆ í™•ì‹  â†’ ê¸°ì–µì—ì„œ ë‹µë³€
                self.stats['answered_from_memory'] += 1
                
                # ğŸª v1.0: ê¸°ì–µ ê¸°ë°˜ ì‘ë‹µ ë¬¸êµ¬ ì •ë¦¬
                best_content = best_memory.get('content', '')
                if best_content:
                    # ğŸ›‘ ì¹˜ëª…ì  ì¶©ëŒ í•´ê²° #1: ì§ˆë¬¸ í•„í„°ë§
                    content_str = str(best_content).strip()
                    if self._is_question_strict(content_str):
                        # ì§ˆë¬¸ì´ë©´ ë‹¤ìŒ ê¸°ì–µ ì°¾ê¸° ë˜ëŠ” ë‹¤ë¥¸ ì²˜ë¦¬
                        if len(memories) > 1:
                            # ë‹¤ìŒ ê¸°ì–µ ì‹œë„
                            for next_memory in memories[1:]:
                                next_content = next_memory.get('content', '')
                                if next_content and not self._is_question_strict(str(next_content)):
                                    # ğŸ“ ì¹˜ëª…ì  ì¶©ëŒ í•´ê²° #2: ì¶œë ¥ í¬ë§·íŒ…
                                    answer = self._format_output(str(next_content), question)
                                    if not self._is_question_strict(answer) and len(answer) > 5:
                                        answer = self._clean_answer(answer, question_keywords)
                                        self._record_knowledge(question, answer, 'memory', next_memory.get('score', 0.5))
                                        self._update_context(question, answer, 'memory')
                                        self.last_question = question
                                        return answer
                        # ì§ˆë¬¸ë§Œ ìˆìœ¼ë©´ ëª¨ë¦„
                        answer = "ê¸°ì–µì´ ëª…í™•í•˜ì§€ ì•Šì•„ìš”."
                    else:
                        # ğŸ“ ì¹˜ëª…ì  ì¶©ëŒ í•´ê²° #2: ì¶œë ¥ í¬ë§·íŒ… íŒŒì´í”„ë¼ì¸ í†µê³¼
                        answer = self._format_output(content_str, question)
                        if not self._is_question_strict(answer) and len(answer) > 5:
                            # ì¤‘ë³µ ì œê±°
                            answer = self._clean_answer(answer, question_keywords)
                        else:
                            answer = "ê¸°ì–µì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤."
                else:
                    answer = "ê´€ë ¨ ê¸°ì–µì´ ìˆì–´ìš”."
                
                # ìµœì¢… ê²€ì¦: ì§ˆë¬¸ì´ ì•„ë‹ˆê³  ì™„ì „í•œ ë¬¸ì¥ì¸ì§€
                if not self._is_question_strict(answer) and len(answer) > 5:
                    self._record_knowledge(question, answer, 'memory', confidence)
                    # ğŸª v1.1: ë§¥ë½ì— ëŒ€í™” ê¸°ë¡ ì¶”ê°€
                    self._update_context(question, answer, 'memory')
                    # ğŸª v1.3: ë§ˆì§€ë§‰ ì§ˆë¬¸ ì €ì¥
                    self.last_question = question
                    return answer
                else:
                    # ë¶ˆì™„ì „í•œ ë‹µë³€ì´ë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ
                    pass
        
        # 2. ê°œì¸ LLM ì‹œë„ (ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„±)
        if self.config.get('use_personal_llm', True) and self.brain.model is not None:
            # ê°œì¸ LLMìœ¼ë¡œ ì§§ì€ ì‘ë‹µ ìƒì„±
            try:
                personal_answer = self._generate_clean_response(question)
                
                if personal_answer:
                    self.stats['answered_from_personal_llm'] += 1
                    
                    # ê¸°ì–µì—ë„ ì €ì¥ (ì§ˆë¬¸ ì œì™¸)
                    # ğŸ›‘ ì¹˜ëª…ì  ì¶©ëŒ í•´ê²° #1: ì§ˆë¬¸ì€ ì €ì¥í•˜ì§€ ì•ŠìŒ
                    learning_content = f"A: {personal_answer[:100]}"
                    if not self._is_question_strict(learning_content):
                        self.brain.learn(
                            learning_content,
                            context="self_answer",
                            importance=0.6
                        )
                    
                    self._record_knowledge(question, personal_answer, 'personal_llm', 0.7)
                    return personal_answer
            except:
                pass
        
        # 3. ë„ì„œê´€ ë°©ë¬¸
        library_answer, success = self.library.ask(question)
        
        if success:
            self.stats['answered_from_library'] += 1
            
            # ë°°ìš´ ê²ƒ ì €ì¥!
            if self.config['learn_from_library']:
                # ğŸ›‘ ì¹˜ëª…ì  ì¶©ëŒ í•´ê²° #1: ì§ˆë¬¸ì€ ì €ì¥í•˜ì§€ ì•ŠìŒ
                # Q: ì§ˆë¬¸ í˜•ì‹ì´ ì•„ë‹Œ, ë‹µë³€ë§Œ ì €ì¥
                learning_content = f"A: {library_answer[:300]}"
                if not self._is_question_strict(learning_content):
                    self.brain.learn(
                        learning_content,
                        context="library_learning",
                        importance=0.8  # ë„ì„œê´€ ì§€ì‹ì€ ì¤‘ìš”
                    )
            
            self._record_knowledge(question, library_answer, 'library', 0.9)
            
            # ìë™ ê³µê³ í™”
            if self.config['auto_consolidate']:
                self.brain.sleep(cycles=2)
            
            # ğŸª v1.1: ë§¥ë½ì— ëŒ€í™” ê¸°ë¡ ì¶”ê°€
            self._update_context(question, library_answer, 'library')
            return f"ğŸ“š {library_answer}"
        
        # 4. ê¸°ì–µì—ì„œë¼ë„ ë­”ê°€ ì°¾ì•„ë³´ê¸°
        # ğŸª v1.4: ì‹¤ì œ ë‹µë³€ì´ ìˆì„ ë•Œë§Œ ë°˜í™˜ (ì§ˆë¬¸ì´ë‚˜ ë¹ˆ ë‚´ìš©ì´ë©´ ë„ì„œê´€ ê°€ê¸°)
        if memories and len(memories) > 0:
            contents = [m.get('content', '') for m in memories if m.get('content')]
            if contents:
                potential_answer = str(contents[0]).strip()
                # ğŸª v1.4: ì§ˆë¬¸ì´ë‚˜ ë¹ˆ ë‚´ìš©ì´ë©´ ë„ì„œê´€ ê°€ê¸°
                if potential_answer and len(potential_answer) > 0:
                    # ì§ˆë¬¸ íŒ¨í„´ì´ ì•„ë‹ˆê³ , ì‹¤ì œ ë‹µë³€ì¸ì§€ í™•ì¸
                    is_question = '?' in potential_answer or potential_answer.endswith('?') or 'ë­' in potential_answer
                    is_empty = len(potential_answer.replace(' ', '').replace('?', '')) == 0
                    
                    if not is_question and not is_empty:
                        # ğŸ“ ì¹˜ëª…ì  ì¶©ëŒ í•´ê²° #2: ì¶œë ¥ í¬ë§·íŒ… íŒŒì´í”„ë¼ì¸ í†µê³¼
                        answer = self._format_output(potential_answer, question)
                        # íŒŒí¸ í•„í„°ë§: ë„ˆë¬´ ì§§ê±°ë‚˜ ë¶ˆì™„ì „í•œ ë‹µë³€ ì°¨ë‹¨
                        if len(answer.strip()) < 3 or answer.strip() in ['ë‚˜', 'ë„ˆ', 'ê·¸', 'ì´', 'ì €', 'ë‚´', 'ë‹¤']:
                            # íŒŒí¸ì´ë©´ ë‹¤ìŒ ë‹¨ê³„ë¡œ
                            pass
                        elif not self._is_question_strict(answer):
                            # ì§ˆë¬¸ì´ ì•„ë‹ˆê³  ì™„ì „í•œ ë¬¸ì¥ì´ë©´ ë°˜í™˜
                            answer = self._clean_answer(answer, [])
                            self._update_context(question, answer, 'memory')
                            return answer
                # ì§ˆë¬¸ì´ê±°ë‚˜ ë¹ˆ ë‚´ìš©ì´ë©´ ë„ì„œê´€ ê°€ê¸° (ì•„ë˜ ì½”ë“œ ê³„ì†)
        
        # 5. ì•„ë¬´ê²ƒë„ ëª¨ë¦„
        # ğŸª v1.3: ë§¥ë½ ê¸°ë°˜ fallback (ì´ì „ ëŒ€í™” ì°¸ì¡°)
        if self.conversation_context:
            # ìµœê·¼ ëŒ€í™”ì™€ ì—°ê´€ì„± ìˆëŠ” ë‹µë³€ ì‹œë„
            last_ctx = self.conversation_context[-1]
            if last_ctx.get('source') == 'learning':
                # ì´ì „ì— í•™ìŠµí–ˆìœ¼ë©´ ê·¸ê²ƒì„ ì–¸ê¸‰
                answer = "ê¸°ì–µì´ ëª…í™•í•˜ì§€ ì•Šì§€ë§Œ, ì´ì „ì— ë°°ìš´ ë‚´ìš©ì´ ìˆì„ ìˆ˜ ìˆì–´ìš”."
            else:
                answer = "ëª¨ë¥´ê² ì–´ìš”."
        else:
            answer = "ëª¨ë¥´ê² ì–´ìš”."
        
        # ğŸª v1.1: ë§¥ë½ì— ëŒ€í™” ê¸°ë¡ ì¶”ê°€
        self._update_context(question, answer, 'general')
        # ğŸª v1.3: ë§ˆì§€ë§‰ ì§ˆë¬¸ ì €ì¥
        self.last_question = question
        return answer
    
    def _format_output(self, raw_content: str, question: str = "") -> str:
        """
        ğŸ“ ì¹˜ëª…ì  ì¶©ëŒ í•´ê²° #2: ì¶œë ¥ í¬ë§·íŒ… íŒŒì´í”„ë¼ì¸
        
        í•´ë§ˆì—ì„œ ì¸ì¶œëœ ê¸°ì–µì„ ì™„ì „í•œ ì„œìˆ í˜• ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜
        
        ì˜ˆ:
            "GNJz" â†’ "ë‹¹ì‹ ì˜ ì´ë¦„ì€ GNJzì…ë‹ˆë‹¤."
            "ë‚´" â†’ "ê¸°ì–µì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤."
            "A" â†’ "AëŠ” ì•ŒíŒŒë²³ ì²« ê¸€ìì…ë‹ˆë‹¤."
        """
        if not raw_content or len(raw_content.strip()) == 0:
            return "ê¸°ì–µì´ ëª…í™•í•˜ì§€ ì•Šì•„ìš”."
        
        content = raw_content.strip()
        
        # 1. ì§ˆë¬¸ í•„í„°ë§: ì§ˆë¬¸ì´ë©´ ë³€í™˜í•˜ì§€ ì•ŠìŒ
        if self._is_question_strict(content):
            return "ê¸°ì–µì´ ëª…í™•í•˜ì§€ ì•Šì•„ìš”."
        
        # 2. íŒŒí¸ í•„í„°ë§: ë„ˆë¬´ ì§§ê±°ë‚˜ ë¶ˆì™„ì „í•œ ë‚´ìš©
        if len(content) < 3:  # ìµœì†Œ 3ê¸€ì ì´ìƒ
            return "ê¸°ì–µì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤."
        
        # 3. ë¶ˆì™„ì „í•œ ë‹¨ì–´ í•„í„°ë§ (ê°•í™”)
        incomplete_words = [
            'ë‚´', 'ë‚˜', 'ë„ˆ', 'ê·¸', 'ì´', 'ì €', 'ë‹¤', 'ê°€', 'ë¥¼', 'ì„', 'ëŠ”', 'ì€',
            'di', 'is', 'the', 'a', 'an', 'it', 'he', 'she', 'we', 'you', 'they'
        ]
        if content.strip() in incomplete_words or content.strip().lower() in incomplete_words:
            return "ê¸°ì–µì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤."
        
        # 4. ë‹¨ì¼ ê¸€ì í•„í„°ë§ (ê°•í™”)
        if len(content.strip()) == 1:
            return "ê¸°ì–µì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤."
        
        # 6. ì´ë¯¸ ì™„ì „í•œ ë¬¸ì¥ì¸ì§€ í™•ì¸
        complete_endings = ['ì…ë‹ˆë‹¤', 'ì´ì—ìš”', 'ì˜ˆìš”', 'ì´ì•¼', 'ê±°ì•¼', 'ì´ë‹¤', 
                           'ì…ë‹ˆë‹¤.', 'ì´ì—ìš”.', 'ì˜ˆìš”.', 'ì´ì•¼.', 'ê±°ì•¼.', 'ì´ë‹¤.',
                           '.', '!', '?']
        if any(content.endswith(ending) for ending in complete_endings):
            # ì´ë¯¸ ì™„ì „í•œ ë¬¸ì¥ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì¤‘ë³µ ì œê±°ë§Œ)
            # í•˜ì§€ë§Œ ì§ˆë¬¸ì´ë©´ í•„í„°ë§
            if self._is_question_strict(content):
                return "ê¸°ì–µì´ ëª…í™•í•˜ì§€ ì•Šì•„ìš”."
            return self._clean_answer(content, [])
        
        # 5. í•™ìŠµ ëª…ë ¹ í˜•íƒœì˜ ê¸°ì–µ í•„í„°ë§ (Echo Effect ë°©ì§€) - ê°•í™”
        # "ë‚˜ëŠ”GNJz ë¼ê³  í•´" ê°™ì€ ë‚ ê²ƒ ê¸°ì–µì„ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜
        learning_command_patterns = ['ë¼ê³  í•´', 'ë¼ê³  í•´ìš”', 'ë¼ê³  í•©ë‹ˆë‹¤', 'ë¼ê³ í•´', 'ë¼ê³ í•´ìš”']
        for pattern in learning_command_patterns:
            if pattern in content:
                # ì´ë¦„ ì¶”ì¶œ
                name_part = content.split(pattern)[0].strip()
                # "ë‚˜ëŠ”", "ì €ëŠ”" ë“± ì œê±°
                for prefix in ['ë‚˜ëŠ”', 'ì €ëŠ”', 'ë‚´ê°€', 'ì œê°€', 'ë‚˜ëŠ”', 'ì €ëŠ”']:
                    if name_part.startswith(prefix):
                        name_part = name_part[len(prefix):].strip()
                # ë„ì–´ì“°ê¸° ì œê±° í›„ í™•ì¸
                name_part_clean = name_part.replace(' ', '')
                if name_part_clean and len(name_part_clean) > 0:
                    # ì§ˆë¬¸ì´ ì•„ë‹ˆê³  ì‹¤ì œ ì´ë¦„ì¸ì§€ í™•ì¸
                    if not self._is_question_strict(name_part_clean):
                        return f"ë‹¹ì‹ ì˜ ì´ë¦„ì€ {name_part_clean}ì…ë‹ˆë‹¤."
                break
        
        # 7. ì§ˆë¬¸ í‚¤ì›Œë“œ ê¸°ë°˜ í¬ë§·íŒ…
        question_lower = question.lower() if question else ""
        
        # ì´ë¦„ ê´€ë ¨ ì§ˆë¬¸
        if 'ì´ë¦„' in question_lower or 'name' in question_lower:
            if len(content) > 1 and content not in ['ë‚´', 'ë‚˜', 'ë„ˆ', 'ê·¸', 'ì´', 'ì €', 'ë‹¤']:
                # ì´ë¯¸ "ë‹¹ì‹ ì˜ ì´ë¦„ì€" ê°™ì€ í˜•ì‹ì´ ì•„ë‹ˆë©´ ì¶”ê°€
                if 'ì´ë¦„' not in content and 'name' not in content.lower():
                    return f"ë‹¹ì‹ ì˜ ì´ë¦„ì€ {content}ì…ë‹ˆë‹¤."
                else:
                    # ì´ë¯¸ ì´ë¦„ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜ (í•˜ì§€ë§Œ ì§ˆë¬¸ì´ë©´ í•„í„°ë§)
                    if self._is_question_strict(content):
                        return "ê¸°ì–µì´ ëª…í™•í•˜ì§€ ì•Šì•„ìš”."
                    return content
        
        # 8. ì¼ë°˜ì ì¸ ë‹µë³€ í¬ë§·íŒ…
        # ê¸°ë³¸: ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ë˜, ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¤ê¸°
        if not any(content.endswith(ending) for ending in complete_endings):
            # ë¬¸ì¥ ì¢…ê²°ì–´ë¯¸ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
            return f"{content}ì…ë‹ˆë‹¤."
        
        # ìµœì¢… ê²€ì¦: ì§ˆë¬¸ì´ë©´ í•„í„°ë§
        if self._is_question_strict(content):
            return "ê¸°ì–µì´ ëª…í™•í•˜ì§€ ì•Šì•„ìš”."
        
        return content
    
    def _clean_answer(self, answer: str, keywords: list) -> str:
        """
        ğŸª v1.0: ë‹µë³€ ì¤‘ë³µ ì œê±°
        
        ì˜ˆ:
            "AëŠ” AëŠ” ì•ŒíŒŒë²³ ì²« ê¸€ìì…ë‹ˆë‹¤." â†’ "AëŠ” ì•ŒíŒŒë²³ ì²« ê¸€ìì…ë‹ˆë‹¤."
            "íŒŒì´ì¬ëŠ” íŒŒì´ì¬ì€..." â†’ "íŒŒì´ì¬ì€..."
        """
        if not answer:
            return answer
        
        # ì¼ë°˜ì ì¸ ì¤‘ë³µ íŒ¨í„´ ì œê±°
        import re
        
        # í‚¤ì›Œë“œë¡œ ì‹œì‘í•˜ëŠ” ì¤‘ë³µ íŒ¨í„´ ì œê±°
        if keywords:
            for keyword in keywords:
                # "í‚¤ì›Œë“œëŠ” í‚¤ì›Œë“œëŠ”" â†’ "í‚¤ì›Œë“œëŠ”"
                patterns = [
                    (f"{keyword}ëŠ” {keyword}ëŠ”", f"{keyword}ëŠ”"),
                    (f"{keyword}ì€ {keyword}ì€", f"{keyword}ì€"),
                    (f"{keyword}ê°€ {keyword}ê°€", f"{keyword}ê°€"),
                    (f"{keyword}ì´ {keyword}ì´", f"{keyword}ì´"),
                    (f"{keyword}ëŠ” {keyword}ì€", f"{keyword}ì€"),
                    (f"{keyword}ì€ {keyword}ëŠ”", f"{keyword}ëŠ”"),
                ]
                for pattern, replacement in patterns:
                    if pattern in answer:
                        answer = answer.replace(pattern, replacement)
        
        # ì¼ë°˜ì ì¸ ì¤‘ë³µ íŒ¨í„´ (í‚¤ì›Œë“œ ì—†ì´ë„)
        # "ë‹¨ì–´ëŠ” ë‹¨ì–´ëŠ”" â†’ "ë‹¨ì–´ëŠ”"
        answer = re.sub(r'(\w+ëŠ”) \1', r'\1', answer)
        answer = re.sub(r'(\w+ì€) \1', r'\1', answer)
        answer = re.sub(r'(\w+ê°€) \1', r'\1', answer)
        answer = re.sub(r'(\w+ì´) \1', r'\1', answer)
        
        return answer.strip()
    
    def _extract_keywords(self, question: str) -> list:
        """
        ğŸª v1.0: ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        
        ì˜ˆ:
            "Aê°€ ë¬´ì—‡ì¸ê°€ìš”?" â†’ ["A"]
            "íŒŒì´ì¬ì´ ë­ì•¼?" â†’ ["íŒŒì´ì¬"]
            "í•´ë§ˆê°€ ë­ì•¼?" â†’ ["í•´ë§ˆ"]
            "ë‚´ ì´ë¦„ ê¸°ì–µë‚˜?" â†’ ["ì´ë¦„", "ê¸°ì–µë‚˜"] (í•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” "GNJz" ì°¾ì•„ì•¼ í•¨)
        """
        # ğŸª v1.0: ì§ˆë¬¸ íŒ¨í„´ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ ê°œì„ 
        question_lower = question.lower()
        
        # "ë‚´ ì´ë¦„", "ë‚´ê°€", "ë‚˜ëŠ”" ê°™ì€ íŒ¨í„´ì—ì„œ ì‹¤ì œ ì´ë¦„ ì¶”ì¶œ ì‹œë„
        if 'ì´ë¦„' in question or 'ê¸°ì–µë‚˜' in question or 'ê¸°ì–µí•´' in question:
            # ì´ë¦„ ê´€ë ¨ ì§ˆë¬¸ â†’ í•™ìŠµëœ ì´ë¦„ ì°¾ê¸°
            # ì¼ë‹¨ ì¼ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ í›„, ê¸°ì–µì—ì„œ ì´ë¦„ ì°¾ê¸°
            pass
        
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = {
            'ê°€', 'ì´', 'ì€', 'ëŠ”', 'ì„', 'ë¥¼', 'ì˜', 'ì—', 'ì™€', 'ê³¼', 
            'ë­', 'ë¬´ì—‡', 'ì¸ê°€ìš”', 'ì•¼', 'ìš”', 'ê¸°ì–µë‚˜', 'ê¸°ì–µí•´', 'ê¸°ì–µí•´ì¤˜',
            'ë‚´', 'ë‚˜', 'ì €', 'ì œ', 'ì´ë¦„', 'ì´ë¦„ì´', 'ì´ë¦„ì€',
            'ë­ì•¼', 'ë­ì˜ˆìš”', 'ë¬´ì—‡ì¸ê°€ìš”', 'ë¬´ì—‡ì´ì•¼',
        }
        
        # ë‹¨ì–´ ë¶„ë¦¬
        words = question.split()
        keywords = []
        
        for word in words:
            # ë¶ˆìš©ì–´ ì œê±°
            cleaned = word.strip('ê°€ì´ì€ë¥¼ì„ì˜ì—ì™€ê³¼ë­ë¬´ì—‡ì¸ê°€ìš”ì•¼ìš”?')
            if cleaned and len(cleaned) > 0 and cleaned not in stopwords:
                keywords.append(cleaned)
        
        # ğŸª v1.0: ì²« ë‹¨ì–´ê°€ í‚¤ì›Œë“œì¼ ê°€ëŠ¥ì„± ë†’ìŒ (í•˜ì§€ë§Œ ë¶ˆìš©ì–´ ì œì™¸)
        if keywords:
            # ë¶ˆìš©ì–´ê°€ ì•„ë‹Œ ì²« ë²ˆì§¸ ë‹¨ì–´
            return keywords[:3]  # ìµœëŒ€ 3ê°œ í‚¤ì›Œë“œ
        return [question]  # í‚¤ì›Œë“œ ì—†ìœ¼ë©´ ì „ì²´ ì§ˆë¬¸ ì‚¬ìš©
    
    def _update_context(self, question: str, answer: str, source: str = 'general'):
        """
        ğŸª v1.1: ëŒ€í™” ë§¥ë½ ì—…ë°ì´íŠ¸
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            answer: AI ë‹µë³€
            source: ë‹µë³€ ì¶œì²˜ ('learning', 'memory', 'library', 'general')
        """
        self.conversation_context.append({
            'question': question,
            'answer': answer,
            'source': source,
        })
        
        # ìµœëŒ€ ë§¥ë½ ìˆ˜ ìœ ì§€
        if len(self.conversation_context) > self.max_context:
            self.conversation_context.pop(0)
    
    def _enhance_with_context(self, question: str) -> str:
        """
        ğŸª v1.3: ë§¥ë½ ê¸°ë°˜ ì§ˆë¬¸ ê°•í™”
        
        ì´ì „ ëŒ€í™”ë¥¼ ì°¸ì¡°í•˜ì—¬ ì§ˆë¬¸ì„ ë” ëª…í™•í•˜ê²Œ ë§Œë“¦
        
        ì˜ˆ:
            "ê·¸ê±°" â†’ ì´ì „ ëŒ€í™”ì˜ ì£¼ì œ
            "ë‚´ ì´ë¦„ì€?" â†’ ì´ì „ì— í•™ìŠµí•œ ì´ë¦„ ì°¸ì¡°
        """
        if not self.conversation_context:
            return question
        
        # ì§€ì‹œì–´ ì²˜ë¦¬ ("ê·¸ê±°", "ê·¸ê±´", "ê·¸ê²ƒ" ë“±)
        reference_words = ['ê·¸ê±°', 'ê·¸ê±´', 'ê·¸ê²ƒ', 'ê·¸ê²Œ', 'ê·¸', 'ì €ê±°', 'ì €ê±´', 'ì €ê²ƒ', 'ì €ê²Œ']
        has_reference = any(word in question for word in reference_words)
        
        if has_reference:
            # ìµœê·¼ ëŒ€í™”ì—ì„œ ì£¼ì œ ì°¾ê¸°
            for ctx in reversed(self.conversation_context[-3:]):  # ìµœê·¼ 3í„´ë§Œ
                prev_question = ctx.get('question', '')
                prev_answer = ctx.get('answer', '')
                
                # ì´ì „ ì§ˆë¬¸/ë‹µë³€ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
                if prev_question:
                    # "ê·¸ê±°"ë¥¼ ì´ì „ ì§ˆë¬¸ì˜ ì£¼ì œë¡œ ëŒ€ì²´
                    for ref_word in reference_words:
                        if ref_word in question:
                            # ì´ì „ ì§ˆë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
                            keywords = self._extract_keywords(prev_question)
                            if keywords:
                                question = question.replace(ref_word, keywords[0])
                                break
        
        # "ë‚´ ì´ë¦„ì€?" ê°™ì€ ì§ˆë¬¸ â†’ ì´ì „ í•™ìŠµí•œ ì´ë¦„ ì°¸ì¡°
        if 'ë‚´ ì´ë¦„' in question or 'ì´ë¦„' in question:
            # ìµœê·¼ ëŒ€í™”ì—ì„œ ì´ë¦„ í•™ìŠµ ì°¾ê¸°
            for ctx in reversed(self.conversation_context[-5:]):  # ìµœê·¼ 5í„´
                if ctx.get('source') == 'learning':
                    prev_q = ctx.get('question', '')
                    # "ë‚´ ì´ë¦„ì€ GNJz" ê°™ì€ íŒ¨í„´ì—ì„œ ì´ë¦„ ì¶”ì¶œ
                    if 'ë‚´ ì´ë¦„ì€' in prev_q or 'ë¼ê³  í•´' in prev_q:
                        # ì´ë¦„ ì¶”ì¶œ ë¡œì§
                        if 'ë‚´ ì´ë¦„ì€' in prev_q:
                            parts = prev_q.split('ë‚´ ì´ë¦„ì€')
                            if len(parts) > 1:
                                name = parts[1].strip().replace('?', '').strip()
                                if name and len(name) > 0:
                                    # ì§ˆë¬¸ì— ì´ë¦„ ì¶”ê°€í•˜ì—¬ ë” ëª…í™•í•˜ê²Œ
                                    question = question.replace('ë‚´ ì´ë¦„', f'ë‚´ ì´ë¦„ {name}')
                                    break
        
        return question
    
    def _generate_clean_response(self, prompt: str) -> str:
        """ê¹”ë”í•œ ì‘ë‹µ ìƒì„± (ê°œì¸ LLM)"""
        if self.brain.model is None:
            return ""
        
        import torch
        
        # ì§§ì€ í”„ë¡¬í”„íŠ¸ë¡œ ì‹œì‘
        start = prompt[:20] if len(prompt) > 20 else prompt
        
        # ì¸ì½”ë”©
        if not hasattr(self.brain, 'stoi') or not self.brain.stoi:
            return ""
        
        tokens = [self.brain.stoi.get(c) for c in start if c in self.brain.stoi]
        if not tokens:
            return ""
        
        x = torch.tensor([tokens], dtype=torch.long, device=self.brain.device)
        
        # ì•„ì£¼ ì§§ê²Œ ìƒì„± (20 í† í°) - CPU ë¶€í•˜ ê°ì†Œ
        with torch.no_grad():
            y = self.brain.model.generate(x, max_new_tokens=20, temperature=0.8, top_k=20)
        
        # ë””ì½”ë”©
        generated = ''.join([self.brain.itos.get(i, '') for i in y[0].tolist()])
        
        # ì²« ë¬¸ì¥ë§Œ ì¶”ì¶œ (. ! ? ì—ì„œ ìë¥´ê¸°)
        for end_char in ['.', '!', '?', '\n']:
            if end_char in generated:
                idx = generated.index(end_char)
                generated = generated[:idx+1]
                break
        
        # ë„ˆë¬´ ì§§ê±°ë‚˜ ì´ìƒí•˜ë©´ ë¬´ì‹œ
        if len(generated) < 5 or generated == start:
            return ""
        
        return generated.strip()
    
    def _is_question_strict(self, text: str) -> bool:
        """
        ğŸ›‘ ì¹˜ëª…ì  ì¶©ëŒ í•´ê²° #1: ì§ˆë¬¸ í•„í„°ë§ v2 (Anti-Contamination Filter v2)
        
        V2: ì§ˆë¬¸ í˜•íƒœì¸ì§€ ê°•ë ¥í•˜ê²Œ ê²€ì‚¬í•˜ì—¬ í•™ìŠµ ê²½ë¡œ ì§„ì…ì„ ë§‰ìŠµë‹ˆë‹¤.
        (ë„ì–´ì“°ê¸°, ë¬¸ì¥ ëì— ë¶™ëŠ” ì˜ë¬¸í˜• ì¢…ê²°ì–´ë¯¸ ì§‘ì¤‘ ê²€ì‚¬)
        
        ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ì§ˆë¬¸ í˜•íƒœì¸ì§€ ê²€ì‚¬í•©ë‹ˆë‹¤.
        (ì§ˆë¬¸ì¼ ê²½ìš°, í•™ìŠµ ì €ì¥ì†Œ(Hippocampus)ë¡œì˜ ì§„ì…ì„ ì°¨ë‹¨í•©ë‹ˆë‹¤.)
        """
        import re
        
        if not text or len(text.strip()) == 0:
            return False
        
        text_clean = text.strip()
        
        # 1. ë¬¼ìŒí‘œ(?) ê²€ì‚¬ (ê°€ì¥ í™•ì‹¤í•¨)
        if text_clean.endswith('?'):
            return True
        
        # 2. ê°•ë ¥í•œ ì˜ë¬¸ íŒ¨í„´ ê²€ì‚¬ (ë„ì–´ì“°ê¸° ë¬´ì‹œ)
        cleaned_text = text_clean.replace(" ", "")
        
        # [í•µì‹¬ ì˜ë¬¸ íŒ¨í„´] ~ì´ì•¼, ~ë­ì•¼, ~ì–´ë•Œ, ~ê°€ìš”, ~ëˆ„êµ¬ì•¼, ~ë‹ˆ, ~í•´
        question_patterns = [
            r'ë­ì•¼$', r'ëˆ„êµ¬ì•¼$', r'ì™œ$', r'ì–´ë•Œ$', r'ì¼ê¹Œ$', r'ã„´ê°€ìš”$', r'ã„¹ê¹Œ$', r'ë‹ˆ$',
            r'ë­ì˜ˆìš”$', r'ë­ì£ $', r'ë­”ê°€ìš”$', r'ë­”ì§€$', r'ë¬´ì—‡ì´ì•¼$', r'ë¬´ì—‡ì¸ê°€ìš”$', r'ë¬´ì—‡ì¸ì§€$',
            r'ì–´ë–»ê²Œ$', r'ì–´ë–¤$', r'ì–¸ì œ$', r'ì–´ë””$', r'ì•Œì•„$', r'ì•Œì§€$',
            r'ê¸°ì–µë‚˜$', r'ê¸°ì–µí•´$', r'ë§ì§€$', r'ì•„ë‹ˆì•¼$', r'ì•„ë‹ˆì§€$',
            r'ì´ë¦„ì´ë­ì•¼$', r'ì´ë¦„ì€ë­ì•¼$', r'ì´ë¦„ì´ë­$', r'ì´ë¦„ì€ë­$',
            r'ë„ˆëŠ”$', r'ë‚˜ëŠ”$', r'ë‹¹ì‹ ì€$', r'ì¿ í‚¤ëŠ”$',
        ]
        
        for pattern in question_patterns:
            if re.search(pattern, cleaned_text):
                return True
        
        # 3. ì¸ì‚¿ë§ì€ ì œì™¸ (Reflex Pathê°€ ì²˜ë¦¬í•˜ë„ë¡)
        if cleaned_text in ["ì•ˆë…•", "ì•ˆë…•í•˜ì„¸ìš”", "ì•ˆë…•í•˜ì„¸ìš”", "ì•ˆë…•íˆê°€ì„¸ìš”"]:
            return False
        
        # 4. ê¸°ì–µ ì¸ì¶œ ìœ ë„ ë¬¸êµ¬ ê²€ì‚¬
        if re.search(r'(ê¸°ì–µë‚˜|í•´ë´|ì•Œë ¤ì¤˜|ë¬´ì—‡ì´|ì–´ë–¤|ë­|ë¬´ì—‡)', cleaned_text):
            # í•˜ì§€ë§Œ í•™ìŠµ ëª…ë ¹ íŒ¨í„´ì€ ì œì™¸
            learning_intro_patterns = ['ë‚´ì´ë¦„ì€', 'ë‚˜ëŠ”', 'ì €ëŠ”', 'ë¼ê³ í•´', 'í•™ìŠµ:', 'ê¸°ì–µí•´']
            has_learning_intro = any(pattern in cleaned_text for pattern in learning_intro_patterns)
            
            if not has_learning_intro:
                return True
        
        # 5. "ì´ë¦„" + ì˜ë¬¸ íŒ¨í„´ ì¡°í•©
        if 'ì´ë¦„' in cleaned_text:
            # "ì´ë¦„ì´ë­ì•¼", "ì´ë¦„ì€ë­ì•¼", "ì´ë¦„ì´ë­", "ì´ë¦„ì€ë­" ë“±
            if re.search(r'ì´ë¦„.*ë­', cleaned_text) or re.search(r'ì´ë¦„.*ë¬´ì—‡', cleaned_text):
                return True
        
        return False
    
    def learn(self, content: str, importance: float = 0.7):
        """
        ì§ì ‘ í•™ìŠµ
        
        ğŸ›‘ ì¹˜ëª…ì  ì¶©ëŒ í•´ê²° #1: ì§ˆë¬¸ì€ ì ˆëŒ€ ì €ì¥í•˜ì§€ ì•ŠìŒ
        """
        # ì§ˆë¬¸ í•„í„°ë§: ì§ˆë¬¸ì´ë©´ í•™ìŠµí•˜ì§€ ì•ŠìŒ
        if self._is_question_strict(content):
            # ì§ˆë¬¸ì€ í•™ìŠµí•˜ì§€ ì•ŠìŒ (ê±°ìš¸ íš¨ê³¼ ë°©ì§€)
            return
        
        self.brain.learn(content, importance=importance)
    
    def sleep(self, cycles: int = 10):
        """ìˆ˜ë©´ (ê³µê³ í™” + LLM ì „ì´)"""
        self.brain.sleep(cycles=cycles)
    
    def grow(self):
        """
        ì„±ì¥ (ê°œì¸ LLM ì¬í•™ìŠµ)
        
        í•´ë§ˆì— ìŒ“ì¸ ê¸°ì–µì„ ê°œì¸ LLMìœ¼ë¡œ ì „ì´
        """
        output_path = self.brain.transfer_to_llm()
        print(f"ğŸ“š ê°œì¸ LLM í•™ìŠµ ë°ì´í„° ìƒì„±: {output_path}")
        print("   ë‹¤ìŒ ë‹¨ê³„: nanoGPTë¡œ ì¬í•™ìŠµ í•„ìš”")
        return output_path
    
    def _record_knowledge(self, question: str, answer: str, 
                          source: str, confidence: float):
        """ì§€ì‹ ê¸°ë¡"""
        key = question[:50]  # ì§ˆë¬¸ ì•ë¶€ë¶„ì„ í‚¤ë¡œ
        
        if key in self.knowledge_base:
            self.knowledge_base[key].access_count += 1
        else:
            self.knowledge_base[key] = LearnedKnowledge(
                question=question,
                answer=answer,
                source=source,
                confidence=confidence
            )
    
    def get_growth_stage(self) -> str:
        """
        ğŸ¦› ì„±ì¥ ë‹¨ê³„ ê³„ì‚°
        
        ê¸°ì–µ ìˆ˜ì™€ í•™ìŠµ íšŸìˆ˜ì— ë”°ë¼ ì„±ì¥ ë‹¨ê³„ ê²°ì •
        
        ì„±ì¥ íë¦„:
        - BabyHippo (ë² ì´ë¹„) â†’ í˜„ì¬ ë‹¨ê³„
        - TeenHippo (í‹´/ìœ ìŠ¤)
        - Hippocampus (ì™„ì „ì²´, ì–´ëœíŠ¸ëŠ” í•„ìš” ì—†ìŒ)
        - WisdomHippo (ì§€í˜œ)
        - MagicHippo (ì‹ ì˜ ê²½ì§€)
        
        Returns:
            'BabyHippo', 'TeenHippo', 'Hippocampus', 'WisdomHippo', 'MagicHippo'
        """
        # ê¸°ì–µ ìˆ˜ í™•ì¸
        brain_stats = self.brain.get_stats()
        memory_count = 0
        if 'hippo' in brain_stats:
            memory_count = brain_stats['hippo'].get('word_count', 0)
        
        # í•™ìŠµ íšŸìˆ˜ í™•ì¸
        learning_count = len(self.knowledge_base)
        total_learning = memory_count + learning_count
        
        # ì„±ì¥ ë‹¨ê³„ ê²°ì •
        if total_learning < 100:
            return 'BabyHippo'  # ë² ì´ë¹„ ë‹¨ê³„
        elif total_learning < 1000:
            return 'TeenHippo'  # í‹´/ìœ ìŠ¤
        elif total_learning < 10000:
            return 'Hippocampus'  # ì™„ì „ì²´ (ì–´ëœíŠ¸ëŠ” í•„ìš” ì—†ìŒ)
        elif total_learning < 100000:
            return 'WisdomHippo'  # ì§€í˜œ
        else:
            return 'MagicHippo'  # ì‹ ì˜ ê²½ì§€
    
    def _update_internal_flags(self):
        """ë‚´ë¶€ ìƒíƒœ í”Œë˜ê·¸ ì—…ë°ì´íŠ¸"""
        # ë‡Œ í†µê³„ì—ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        brain_stats = self.brain.get_stats()
        
        # ë‰´ëŸ° ìˆ˜ (í•´ë§ˆì—ì„œ)
        if 'hippo' in brain_stats:
            # ëŒ€ëµì  ì¶”ì •: word_count * 10 (ê° ê¸°ì–µë‹¹ í‰ê·  10ê°œ ë‰´ëŸ°)
            word_count = brain_stats['hippo'].get('word_count', 0)
            self.internal_flags['neuron_count'] = word_count * 10
        
        # ê¸°ëŠ¥ í”Œë˜ê·¸ (ê¸°ë³¸ì ìœ¼ë¡œ BASIC_STDPëŠ” í•­ìƒ ìˆìŒ)
        self.internal_flags['features'].add(NetworkFeature.BASIC_STDP)
        
        # ëª¨ë¸ í”Œë˜ê·¸ (HHSomaQuick ê¸°ë³¸ ì‚¬ìš©)
        self.internal_flags['models'].add(NeuronModel.HH_QUICK)
        
        # TODO: ì‹¤ì œ FPS, Axon ë…¸ë“œ ìˆ˜, ì¶”ê°€ ê¸°ëŠ¥/ëª¨ë¸ ì¸¡ì •
    
    def _update_capability_schema(self):
        """BrainCapability Schema ì—…ë°ì´íŠ¸"""
        # Memory
        self.capability_schema.set_capability(
            CapabilityCategory.MEMORY, "short_term", 
            enabled=True, level=1.0
        )
        self.capability_schema.set_capability(
            CapabilityCategory.MEMORY, "working",
            enabled=True, level=1.0
        )
        
        # Plasticity
        self.capability_schema.set_capability(
            CapabilityCategory.PLASTICITY, "stdp",
            enabled=True, level=1.0
        )
        
        # TODO: ì‹¤ì œ êµ¬í˜„ ìƒíƒœì— ë”°ë¼ ì—…ë°ì´íŠ¸
    
    def get_stats(self) -> Dict:
        """í†µê³„"""
        brain_stats = self.brain.get_stats()
        library_stats = self.library.get_stats()
        
        # ì„±ì¥ë„ ê³„ì‚°
        total_answered = (
            self.stats['answered_from_memory'] + 
            self.stats['answered_from_personal_llm']
        )
        total_questions = self.stats['questions_asked']
        
        independence = (total_answered / total_questions * 100) if total_questions > 0 else 0
        
        # ğŸ¦› ì„±ì¥ ë‹¨ê³„ ì¶”ê°€
        growth_stage = self.get_growth_stage()
        
        # ë‚´ë¶€ ìƒíƒœ í”Œë˜ê·¸ ì—…ë°ì´íŠ¸
        self._update_internal_flags()
        
        return {
            'name': self.name,
            'growth_stage': growth_stage,  # ğŸ¦› ì„±ì¥ ë‹¨ê³„
            'questions': self.stats,
            'brain': brain_stats,
            'library': library_stats,
            'knowledge_count': len(self.knowledge_base),
            'independence': f"{independence:.1f}%",  # ë„ì„œê´€ ë…ë¦½ë„
            'internal_flags': {  # ğŸ¦› ë‚´ë¶€ ìƒíƒœ í”Œë˜ê·¸ (í•˜ìœ„ í˜¸í™˜ì„±)
                'neuron_count': self.internal_flags['neuron_count'],
                'fps': self.internal_flags['fps'],
                'axon_nodes': self.internal_flags['axon_nodes'],
                'features': [f.value for f in self.internal_flags['features']],
                'models': [m.value for m in self.internal_flags['models']],
                'stability_test_passed': self.internal_flags['stability_test_passed'],
                'robustness_test_passed': self.internal_flags['robustness_test_passed'],
            },
            'capability_schema': self.capability_schema.to_dict(),  # ğŸ§© BrainCapability Schema
        }
    
    def __repr__(self):
        stats = self.get_stats()
        return f"CuriousBrain('{self.name}', independence={stats['independence']})"


# =========================================================
# ğŸ§ª TEST
# =========================================================

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ§  CuriousBrain - ëª¨ë“  ê±¸ ì•Œê³  ì‹¶ì€ AI")
    print("=" * 60)
    
    # í˜¸ê¸°ì‹¬ ë‡Œ ìƒì„±
    brain = CuriousBrain(name="baby")
    
    print(f"\nğŸ”§ {brain}")
    print(f"   ë„ì„œê´€: {brain.library.get_stats()}")
    
    # ì§ì ‘ í•™ìŠµ
    print("\nğŸ“ ì§ì ‘ í•™ìŠµ...")
    brain.learn("ì œ ì´ë¦„ì€ babyhippoì…ë‹ˆë‹¤", importance=0.9)
    brain.learn("ì €ëŠ” í˜¸ê¸°ì‹¬ì´ ë§ì€ AIì…ë‹ˆë‹¤", importance=0.9)
    brain.learn("íŒŒì´ì¬ì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤", importance=0.8)
    
    # ìˆ˜ë©´
    brain.sleep(cycles=5)
    
    # ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
    print("\nğŸ¤” ì§ˆë¬¸ í…ŒìŠ¤íŠ¸:")
    
    questions = [
        "ë„ˆì˜ ì´ë¦„ì´ ë­ì•¼?",  # ê¸°ì–µì— ìˆìŒ
        "íŒŒì´ì¬ì´ ë­ì•¼?",     # ê¸°ì–µì— ìˆìŒ
        "ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ?",    # ê¸°ì–µì— ì—†ìŒ â†’ ë„ì„œê´€
    ]
    
    for q in questions:
        print(f"\nQ: {q}")
        answer = brain.think(q)
        print(f"A: {answer[:150]}...")
    
    # í†µê³„
    print("\nğŸ“Š í†µê³„:")
    stats = brain.get_stats()
    print(f"   ì§ˆë¬¸ ìˆ˜: {stats['questions']['questions_asked']}")
    print(f"   ê¸°ì–µ ë‹µë³€: {stats['questions']['answered_from_memory']}")
    print(f"   ê°œì¸LLM ë‹µë³€: {stats['questions']['answered_from_personal_llm']}")
    print(f"   ë„ì„œê´€ ë‹µë³€: {stats['questions']['answered_from_library']}")
    print(f"   ë…ë¦½ë„: {stats['independence']}")
    
    print("\n" + "=" * 60)
    print("âœ… í˜¸ê¸°ì‹¬ AI í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("   â†’ ë„ì„œê´€ API ì—°ê²°í•˜ë©´ ì§„ì§œ í•™ìŠµ ì‹œì‘!")
    print("=" * 60)

