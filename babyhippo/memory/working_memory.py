"""
PersistentWorkingMemory: ì˜êµ¬ ì‘ì—… ê¸°ì–µ

ì„¸ì…˜ ì¢…ë£Œ, ì¬ë¶€íŒ…, í•œ ë‹¬ í›„ì—ë„ ì‘ì—… ë‚´ìš©ì„ ê¸°ì–µí•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ì½”ë“œ/ë¬¸ì„œ ì „ì²´ ì €ì¥ (ìš”ì•½ ì•„ë‹Œ ì›ë³¸)
- ìµœëŒ€ Nê°œ ìŠ¬ë¡¯ (ê¸°ë³¸ 3ê°œ)
- LRU + ì¤‘ìš”ë„ ê¸°ë°˜ ìë™ êµì²´
- SQLite ì˜êµ¬ ì €ì¥
- ì„¸ì…˜ ì‹œì‘ ì‹œ ìë™ ë³µì›

ì‚¬ìš©ë²•:
    memory = PersistentWorkingMemory()
    
    # ì½”ë“œ ì €ì¥
    memory.save_work("brain_graph.py", code_content, work_type="code")
    
    # ë³µì› (ìë™)
    recent_works = memory.get_recent_works()
    
    # AI ì»¨í…ìŠ¤íŠ¸ìš©
    context = memory.get_context_for_ai()
"""

import sqlite3
import time
import hashlib
import json
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime


class PersistentWorkingMemory:
    """
    ì˜êµ¬ ì‘ì—… ê¸°ì–µ
    
    íŠ¹ì§•:
    - ì½”ë“œ/ë¬¸ì„œ ì „ì²´ ì €ì¥ (ìµœëŒ€ 100KB per slot)
    - ìŠ¬ë¡¯ ê¸°ë°˜ ê´€ë¦¬ (ê¸°ë³¸ 3ê°œ)
    - ì¤‘ìš”ë„ + ìµœê·¼ì„± ê¸°ë°˜ êµì²´
    - SQLite ì˜êµ¬ ì €ì¥
    """
    
    VERSION = "1.0.0"
    
    def __init__(
        self,
        db_path: str = None,
        max_slots: int = 3,
        max_size_per_slot: int = 100000,  # 100KB (ì•½ 2000ì¤„)
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            db_path: DB íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ ê²½ë¡œ)
            max_slots: ìµœëŒ€ ìŠ¬ë¡¯ ìˆ˜
            max_size_per_slot: ìŠ¬ë¡¯ë‹¹ ìµœëŒ€ í¬ê¸° (bytes)
        """
        self.max_slots = max_slots
        self.max_size = max_size_per_slot
        
        # DB ê²½ë¡œ ì„¤ì •
        if db_path is None:
            db_dir = Path.home() / ".babyhippo"
            db_dir.mkdir(exist_ok=True)
            db_path = str(db_dir / "working_memory.db")
        
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path, check_same_thread=False)
        self._init_db()
        
        # í†µê³„
        self.total_saves = 0
        self.total_restores = 0
    
    def _init_db(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        cursor = self.conn.cursor()
        
        # ì‘ì—… ìŠ¬ë¡¯ í…Œì´ë¸”
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS work_slots (
                id TEXT PRIMARY KEY,
                name TEXT NOT NULL,
                content TEXT NOT NULL,
                work_type TEXT DEFAULT 'code',
                summary TEXT,
                importance REAL DEFAULT 0.5,
                access_count INTEGER DEFAULT 0,
                created_at REAL NOT NULL,
                last_accessed REAL NOT NULL,
                metadata TEXT
            )
        ''')
        
        # ì‘ì—… íˆìŠ¤í† ë¦¬ (ì‚­ì œëœ ì‘ì—…ë„ ìš”ì•½ ë³´ê´€)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS work_history (
                id TEXT PRIMARY KEY,
                name TEXT NOT NULL,
                summary TEXT,
                work_type TEXT,
                created_at REAL,
                deleted_at REAL,
                total_accesses INTEGER
            )
        ''')
        
        # ì„¸ì…˜ ë¡œê·¸ (ì–¸ì œ ì‘ì—…í–ˆëŠ”ì§€)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS session_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                started_at REAL NOT NULL,
                ended_at REAL,
                works_accessed TEXT
            )
        ''')
        
        self.conn.commit()
    
    def save_work(
        self,
        name: str,
        content: str,
        work_type: str = "code",
        importance: float = 0.5,
        metadata: Dict = None
    ) -> str:
        """
        ì‘ì—… ì €ì¥
        
        Args:
            name: ì‘ì—… ì´ë¦„ (ì˜ˆ: "brain_graph.py")
            content: ì „ì²´ ë‚´ìš©
            work_type: ì‘ì—… ìœ í˜• (code, document, notes)
            importance: ì¤‘ìš”ë„ (0.0 ~ 1.0)
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°
        
        Returns:
            work_id: ì €ì¥ëœ ì‘ì—… ID
        """
        # í¬ê¸° ì œí•œ
        if len(content) > self.max_size:
            content = content[:self.max_size]
            # ë§ˆì§€ë§‰ ì™„ì „í•œ ì¤„ê¹Œì§€ë§Œ
            last_newline = content.rfind('\n')
            if last_newline > 0:
                content = content[:last_newline]
        
        # ID ìƒì„± (ì´ë¦„ ê¸°ë°˜ - ê°™ì€ íŒŒì¼ì€ ì—…ë°ì´íŠ¸)
        work_id = self._generate_id(name)
        
        # ìš”ì•½ ìƒì„±
        summary = self._generate_summary(name, content, work_type)
        
        now = time.time()
        
        cursor = self.conn.cursor()
        
        # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì—…ë°ì´íŠ¸
        cursor.execute('SELECT id, access_count FROM work_slots WHERE id = ?', (work_id,))
        existing = cursor.fetchone()
        
        if existing:
            # ì—…ë°ì´íŠ¸
            access_count = existing[1] + 1
            cursor.execute('''
                UPDATE work_slots 
                SET content = ?, summary = ?, importance = ?, 
                    access_count = ?, last_accessed = ?, metadata = ?
                WHERE id = ?
            ''', (content, summary, importance, access_count, now,
                  json.dumps(metadata or {}), work_id))
        else:
            # ìŠ¬ë¡¯ í™•ì¸
            cursor.execute('SELECT COUNT(*) FROM work_slots')
            count = cursor.fetchone()[0]
            
            if count >= self.max_slots:
                # ê°€ì¥ ì˜¤ë˜ë˜ê³  ëœ ì¤‘ìš”í•œ ê²ƒ ì œê±°
                self._evict_oldest()
            
            # ìƒˆë¡œ ì €ì¥
            cursor.execute('''
                INSERT INTO work_slots 
                (id, name, content, work_type, summary, importance, 
                 access_count, created_at, last_accessed, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (work_id, name, content, work_type, summary, importance,
                  1, now, now, json.dumps(metadata or {})))
        
        self.conn.commit()
        self.total_saves += 1
        
        return work_id
    
    def get_work(self, name: str) -> Optional[Dict]:
        """íŠ¹ì • ì‘ì—… ì¡°íšŒ"""
        work_id = self._generate_id(name)
        
        cursor = self.conn.cursor()
        cursor.execute('''
            SELECT id, name, content, work_type, summary, importance,
                   access_count, created_at, last_accessed, metadata
            FROM work_slots WHERE id = ?
        ''', (work_id,))
        
        row = cursor.fetchone()
        if not row:
            return None
        
        # ì ‘ê·¼ ê¸°ë¡ ì—…ë°ì´íŠ¸
        cursor.execute('''
            UPDATE work_slots 
            SET access_count = access_count + 1, last_accessed = ?
            WHERE id = ?
        ''', (time.time(), work_id))
        self.conn.commit()
        
        return {
            'id': row[0],
            'name': row[1],
            'content': row[2],
            'work_type': row[3],
            'summary': row[4],
            'importance': row[5],
            'access_count': row[6],
            'created_at': row[7],
            'last_accessed': row[8],
            'metadata': json.loads(row[9]) if row[9] else {}
        }
    
    def get_recent_works(self, limit: int = None) -> List[Dict]:
        """ìµœê·¼ ì‘ì—… ëª©ë¡ ì¡°íšŒ"""
        if limit is None:
            limit = self.max_slots
        
        cursor = self.conn.cursor()
        cursor.execute('''
            SELECT id, name, content, work_type, summary, importance,
                   access_count, created_at, last_accessed, metadata
            FROM work_slots 
            ORDER BY last_accessed DESC
            LIMIT ?
        ''', (limit,))
        
        works = []
        for row in cursor.fetchall():
            works.append({
                'id': row[0],
                'name': row[1],
                'content': row[2],
                'work_type': row[3],
                'summary': row[4],
                'importance': row[5],
                'access_count': row[6],
                'created_at': row[7],
                'last_accessed': row[8],
                'metadata': json.loads(row[9]) if row[9] else {}
            })
        
        self.total_restores += 1
        return works
    
    def get_context_for_ai(self, max_chars: int = 50000) -> str:
        """
        AIì—ê²Œ ì „ë‹¬í•  ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        
        Returns:
            AIê°€ ì°¸ê³ í•  ì‘ì—… ê¸°ì–µ ë¬¸ìì—´
        """
        works = self.get_recent_works()
        
        if not works:
            return ""
        
        context_parts = ["[ğŸ“ ì‘ì—… ê¸°ì–µ - ì´ì „ ì„¸ì…˜ì—ì„œ ì‘ì—…í•œ ë‚´ìš©]\n"]
        total_chars = 0
        
        for i, work in enumerate(works, 1):
            # ì‹œê°„ í¬ë§·
            last_time = datetime.fromtimestamp(work['last_accessed'])
            time_str = last_time.strftime("%Y-%m-%d %H:%M")
            
            # í—¤ë”
            header = f"\n### {i}. {work['name']} ({work['work_type']})\n"
            header += f"ë§ˆì§€ë§‰ ì‘ì—…: {time_str} | ì ‘ê·¼: {work['access_count']}íšŒ\n"
            header += f"ìš”ì•½: {work['summary']}\n"
            header += "```\n"
            
            # ë‚´ìš© (ë‚¨ì€ ê³µê°„ë§Œí¼)
            remaining = max_chars - total_chars - len(header) - 100
            if remaining <= 0:
                break
            
            content = work['content']
            if len(content) > remaining:
                content = content[:remaining] + "\n... (truncated)"
            
            footer = "\n```\n"
            
            part = header + content + footer
            context_parts.append(part)
            total_chars += len(part)
        
        return "".join(context_parts)
    
    def get_summary_context(self) -> str:
        """ìš”ì•½ë§Œ í¬í•¨í•œ ì»¨í…ìŠ¤íŠ¸ (ê°€ë²¼ìš´ ë²„ì „)"""
        works = self.get_recent_works()
        
        if not works:
            return ""
        
        lines = ["[ğŸ“ ìµœê·¼ ì‘ì—… ìš”ì•½]"]
        for work in works:
            last_time = datetime.fromtimestamp(work['last_accessed'])
            time_str = last_time.strftime("%m/%d %H:%M")
            lines.append(f"- {work['name']}: {work['summary']} ({time_str})")
        
        return "\n".join(lines)
    
    def delete_work(self, name: str) -> bool:
        """ì‘ì—… ì‚­ì œ (íˆìŠ¤í† ë¦¬ì— ìš”ì•½ ë³´ê´€)"""
        work_id = self._generate_id(name)
        
        cursor = self.conn.cursor()
        
        # ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ
        cursor.execute('''
            SELECT name, summary, work_type, created_at, access_count
            FROM work_slots WHERE id = ?
        ''', (work_id,))
        row = cursor.fetchone()
        
        if not row:
            return False
        
        # íˆìŠ¤í† ë¦¬ì— ë³´ê´€
        cursor.execute('''
            INSERT OR REPLACE INTO work_history
            (id, name, summary, work_type, created_at, deleted_at, total_accesses)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (work_id, row[0], row[1], row[2], row[3], time.time(), row[4]))
        
        # ìŠ¬ë¡¯ì—ì„œ ì‚­ì œ
        cursor.execute('DELETE FROM work_slots WHERE id = ?', (work_id,))
        
        self.conn.commit()
        return True
    
    def clear_all(self):
        """ëª¨ë“  ì‘ì—… ì‚­ì œ (ì£¼ì˜!)"""
        cursor = self.conn.cursor()
        
        # íˆìŠ¤í† ë¦¬ì— ë°±ì—…
        cursor.execute('''
            INSERT INTO work_history 
            (id, name, summary, work_type, created_at, deleted_at, total_accesses)
            SELECT id, name, summary, work_type, created_at, ?, access_count
            FROM work_slots
        ''', (time.time(),))
        
        cursor.execute('DELETE FROM work_slots')
        self.conn.commit()
    
    def get_stats(self) -> Dict:
        """í†µê³„ ì¡°íšŒ"""
        cursor = self.conn.cursor()
        
        cursor.execute('SELECT COUNT(*) FROM work_slots')
        slot_count = cursor.fetchone()[0]
        
        cursor.execute('SELECT SUM(LENGTH(content)) FROM work_slots')
        total_size = cursor.fetchone()[0] or 0
        
        cursor.execute('SELECT COUNT(*) FROM work_history')
        history_count = cursor.fetchone()[0]
        
        return {
            'version': self.VERSION,
            'db_path': self.db_path,
            'max_slots': self.max_slots,
            'used_slots': slot_count,
            'total_size_bytes': total_size,
            'total_size_kb': round(total_size / 1024, 2),
            'history_count': history_count,
            'total_saves': self.total_saves,
            'total_restores': self.total_restores,
        }
    
    def log_session_start(self):
        """ì„¸ì…˜ ì‹œì‘ ë¡œê·¸"""
        cursor = self.conn.cursor()
        cursor.execute('''
            INSERT INTO session_log (started_at) VALUES (?)
        ''', (time.time(),))
        self.conn.commit()
        return cursor.lastrowid
    
    def log_session_end(self, session_id: int, works_accessed: List[str]):
        """ì„¸ì…˜ ì¢…ë£Œ ë¡œê·¸"""
        cursor = self.conn.cursor()
        cursor.execute('''
            UPDATE session_log 
            SET ended_at = ?, works_accessed = ?
            WHERE id = ?
        ''', (time.time(), json.dumps(works_accessed), session_id))
        self.conn.commit()
    
    # ===== Private Methods =====
    
    def _generate_id(self, name: str) -> str:
        """ì´ë¦„ ê¸°ë°˜ ID ìƒì„± (ê°™ì€ íŒŒì¼ì€ ê°™ì€ ID)"""
        return hashlib.md5(name.lower().encode()).hexdigest()[:12]
    
    def _generate_summary(self, name: str, content: str, work_type: str) -> str:
        """ì‘ì—… ìš”ì•½ ìƒì„±"""
        lines = content.split('\n')
        line_count = len(lines)
        
        # ì½”ë“œ íƒ€ì…ë³„ ìš”ì•½
        if work_type == 'code':
            # í´ë˜ìŠ¤/í•¨ìˆ˜ ì°¾ê¸°
            classes = [l.strip() for l in lines if l.strip().startswith('class ')]
            functions = [l.strip() for l in lines if l.strip().startswith('def ')]
            
            summary_parts = [f"{line_count}ì¤„"]
            if classes:
                summary_parts.append(f"í´ë˜ìŠ¤ {len(classes)}ê°œ")
            if functions:
                summary_parts.append(f"í•¨ìˆ˜ {len(functions)}ê°œ")
            
            return f"{name} - " + ", ".join(summary_parts)
        
        else:
            # ë¬¸ì„œ
            char_count = len(content)
            return f"{name} - {line_count}ì¤„, {char_count}ì"
    
    def _evict_oldest(self):
        """ê°€ì¥ ì˜¤ë˜ë˜ê³  ëœ ì¤‘ìš”í•œ ì‘ì—… ì œê±°"""
        cursor = self.conn.cursor()
        
        # ì ìˆ˜ ê³„ì‚°: importance * 0.3 + recency * 0.4 + access * 0.3
        cursor.execute('''
            SELECT id, name, summary, work_type, created_at, access_count,
                   importance, last_accessed
            FROM work_slots
            ORDER BY 
                (importance * 0.3 + 
                 (last_accessed - ?) / 86400.0 * 0.4 + 
                 MIN(access_count, 10) / 10.0 * 0.3)
            ASC
            LIMIT 1
        ''', (time.time(),))
        
        row = cursor.fetchone()
        if row:
            work_id = row[0]
            
            # íˆìŠ¤í† ë¦¬ì— ë³´ê´€
            cursor.execute('''
                INSERT OR REPLACE INTO work_history
                (id, name, summary, work_type, created_at, deleted_at, total_accesses)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (work_id, row[1], row[2], row[3], row[4], time.time(), row[5]))
            
            # ì‚­ì œ
            cursor.execute('DELETE FROM work_slots WHERE id = ?', (work_id,))
            self.conn.commit()
    
    def close(self):
        """ì—°ê²° ì¢…ë£Œ"""
        self.conn.close()


# ===== í¸ì˜ í•¨ìˆ˜ =====

def create_working_memory(max_slots: int = 3) -> PersistentWorkingMemory:
    """ì‘ì—… ê¸°ì–µ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return PersistentWorkingMemory(max_slots=max_slots)


# ===== ì½”ë“œ ê°ì§€ ìœ í‹¸ =====

def detect_code_in_message(message: str) -> Optional[Dict]:
    """
    ë©”ì‹œì§€ì—ì„œ ì½”ë“œ ê°ì§€
    
    Returns:
        {'name': íŒŒì¼ëª…, 'content': ì½”ë“œ, 'type': 'code'} or None
    """
    # ì½”ë“œ ë¸”ë¡ íŒ¨í„´
    import re
    
    # ```python ... ``` í˜•ì‹
    code_block = re.search(r'```(\w+)?\n(.*?)```', message, re.DOTALL)
    if code_block:
        lang = code_block.group(1) or 'code'
        code = code_block.group(2).strip()
        if len(code) > 100:  # ìµœì†Œ 100ì ì´ìƒ
            return {
                'name': f'code_snippet.{lang}',
                'content': code,
                'type': 'code'
            }
    
    # íŒŒì¼ ë‚´ìš©ì²˜ëŸ¼ ë³´ì´ëŠ” ê²½ìš° (class, def, import ë“±)
    if len(message) > 200:
        code_indicators = ['class ', 'def ', 'import ', 'from ', 'function ', 'const ', 'let ', 'var ']
        indicator_count = sum(1 for ind in code_indicators if ind in message)
        
        if indicator_count >= 2:
            # íŒŒì¼ëª… ì¶”ì¶œ ì‹œë„
            filename_match = re.search(r'(\w+\.py|\w+\.js|\w+\.ts)', message)
            filename = filename_match.group(1) if filename_match else 'detected_code.txt'
            
            return {
                'name': filename,
                'content': message,
                'type': 'code'
            }
    
    return None

