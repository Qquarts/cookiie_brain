"""
Stimulus Accumulator: ìžê·¹ ì¶•ì  ì‹œìŠ¤í…œ

ðŸ§  ê°œë…:
    ê¸°ì–µ = ë‹¨ìˆœ ì €ìž¥ âŒ
    ê¸°ì–µ = ìžê·¹ì˜ ì¶•ì  â†’ íŒ¨í„´ í˜•ì„± â†’ (ì„±ê²© emergence)
    
    ì„±ê²© ìžì²´ë¥¼ êµ¬í˜„í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼,
    ì„±ê²©ì´ "í˜•ì„±ë  ìˆ˜ ìžˆëŠ”" êµ¬ì¡°ë¥¼ ë§Œë“œëŠ” ê²ƒ.
    
    ì‹¤ì œ ì„±ê²© í˜•ì„±ì€ ê´€ì°°/ì‹¤í—˜ ì˜ì—­.

êµ¬ì¡°:
    1. Stimulus (ìžê·¹): ê°œë³„ ìž…ë ¥ê³¼ ê·¸ ê°•ë„
    2. Accumulation (ì¶•ì ): ìžê·¹ì´ ìŒ“ì´ëŠ” ê³¼ì •
    3. Pattern (íŒ¨í„´): ì¶•ì ëœ ìžê·¹ì˜ ë¶„í¬/ê²½í–¥
    4. Trace (í”ì ): íŒ¨í„´ì´ ë‚¨ê¸´ ìž”ìƒ (ì„±ê²© í˜•ì„±ì˜ ìž¬ë£Œ)

ì‚¬ìš©:
    accumulator = StimulusAccumulator()
    accumulator.receive("ê³ ì–‘ì´", intensity=0.8, valence=1.0)  # ê¸ì • ìžê·¹
    accumulator.receive("ê³ ì–‘ì´", intensity=0.5, valence=1.0)  # ë°˜ë³µ
    patterns = accumulator.get_patterns()  # ì¶•ì ëœ íŒ¨í„´ ê´€ì°°
    
Author: GNJz (Qquarts)
Version: 1.0
"""

import time
import json
import math
from collections import defaultdict
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path


class Stimulus:
    """
    ê°œë³„ ìžê·¹
    
    Attributes:
        content: ìžê·¹ ë‚´ìš© (í‚¤ì›Œë“œ, ì£¼ì œ, ê°œë… ë“±)
        intensity: ìžê·¹ ê°•ë„ (0.0 ~ 1.0)
        valence: ê°ì •ê°€ (-1.0=ë¶€ì •, 0=ì¤‘ë¦½, +1.0=ê¸ì •)
        timestamp: ë°œìƒ ì‹œê°„
        context: ë§¥ë½
    """
    def __init__(self, 
                 content: str,
                 intensity: float = 0.5,
                 valence: float = 0.0,
                 context: str = None):
        self.content = content
        self.intensity = max(0.0, min(1.0, intensity))
        self.valence = max(-1.0, min(1.0, valence))
        self.context = context
        self.timestamp = time.time()
    
    def to_dict(self) -> Dict:
        return {
            'content': self.content,
            'intensity': self.intensity,
            'valence': self.valence,
            'context': self.context,
            'timestamp': self.timestamp
        }
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'Stimulus':
        s = cls(
            content=data['content'],
            intensity=data.get('intensity', 0.5),
            valence=data.get('valence', 0.0),
            context=data.get('context')
        )
        s.timestamp = data.get('timestamp', time.time())
        return s


class AccumulatedTrace:
    """
    ì¶•ì ëœ í”ì  (íŠ¹ì • ì£¼ì œ/ê°œë…ì— ëŒ€í•œ ëˆ„ì  ìžê·¹)
    
    ì´ê²ƒì´ ì„±ê²© í˜•ì„±ì˜ "ìž¬ë£Œ"ê°€ ë¨.
    ì§ì ‘ ì„±ê²©ì„ ì •ì˜í•˜ì§€ ì•Šê³ , ê´€ì°° ê°€ëŠ¥í•œ ë°ì´í„°ë¥¼ ì œê³µ.
    """
    def __init__(self, key: str):
        self.key = key  # ì£¼ì œ/ê°œë…/í‚¤ì›Œë“œ
        
        # === ì¶•ì  ë°ì´í„° ===
        self.total_intensity = 0.0      # ì´ ìžê·¹ ê°•ë„
        self.total_valence = 0.0        # ì´ ê°ì •ê°€
        self.exposure_count = 0         # ë…¸ì¶œ íšŸìˆ˜
        self.first_exposure = None      # ì²« ë…¸ì¶œ ì‹œê°„
        self.last_exposure = None       # ë§ˆì§€ë§‰ ë…¸ì¶œ ì‹œê°„
        
        # === ë¶„í¬ ë°ì´í„° ===
        self.intensity_history = []     # ê°•ë„ ì´ë ¥ (ìµœê·¼ Nê°œ)
        self.valence_history = []       # ê°ì •ê°€ ì´ë ¥
        self.interval_history = []      # ë…¸ì¶œ ê°„ê²© ì´ë ¥
        
        # === íŒŒìƒ ì§€í‘œ (ê´€ì°°ìš©) ===
        # ì´ê²ƒë“¤ì´ "ì„±ê²©"ìœ¼ë¡œ í•´ì„ë  ìˆ˜ ìžˆëŠ” ë°ì´í„°
        self.avg_intensity = 0.0        # í‰ê·  ê°•ë„
        self.avg_valence = 0.0          # í‰ê·  ê°ì •ê°€ (ì¢‹ì•„í•¨/ì‹«ì–´í•¨)
        self.consistency = 0.0          # ì¼ê´€ì„± (í•­ìƒ ë¹„ìŠ·í•œ ë°˜ì‘?)
        self.recency_weight = 0.0       # ìµœê·¼ì„± ê°€ì¤‘ì¹˜
        
        # ì„¤ì •
        self.history_limit = 100        # ì´ë ¥ ë³´ê´€ ìˆ˜
    
    def accumulate(self, stimulus: Stimulus):
        """ìžê·¹ ì¶•ì """
        now = stimulus.timestamp
        
        # ì²« ë…¸ì¶œ ê¸°ë¡
        if self.first_exposure is None:
            self.first_exposure = now
        
        # ê°„ê²© ê¸°ë¡
        if self.last_exposure is not None:
            interval = now - self.last_exposure
            self.interval_history.append(interval)
            if len(self.interval_history) > self.history_limit:
                self.interval_history.pop(0)
        
        self.last_exposure = now
        
        # ì¶•ì 
        self.total_intensity += stimulus.intensity
        self.total_valence += stimulus.valence * stimulus.intensity  # ê°•ë„ ê°€ì¤‘
        self.exposure_count += 1
        
        # ì´ë ¥ ì¶”ê°€
        self.intensity_history.append(stimulus.intensity)
        self.valence_history.append(stimulus.valence)
        
        if len(self.intensity_history) > self.history_limit:
            self.intensity_history.pop(0)
        if len(self.valence_history) > self.history_limit:
            self.valence_history.pop(0)
        
        # íŒŒìƒ ì§€í‘œ ì—…ë°ì´íŠ¸
        self._update_derived_metrics()
    
    def _update_derived_metrics(self):
        """íŒŒìƒ ì§€í‘œ ê³„ì‚°"""
        if self.exposure_count == 0:
            return
        
        # í‰ê·  ê°•ë„
        self.avg_intensity = self.total_intensity / self.exposure_count
        
        # í‰ê·  ê°ì •ê°€ (ê°•ë„ ê°€ì¤‘ í‰ê· )
        if self.total_intensity > 0:
            self.avg_valence = self.total_valence / self.total_intensity
        
        # ì¼ê´€ì„± (í‘œì¤€íŽ¸ì°¨ì˜ ì—­ìˆ˜ ê¸°ë°˜)
        if len(self.valence_history) > 1:
            import statistics
            try:
                std = statistics.stdev(self.valence_history)
                self.consistency = 1.0 / (1.0 + std)  # 0~1, ë†’ì„ìˆ˜ë¡ ì¼ê´€
            except:
                self.consistency = 1.0
        
        # ìµœê·¼ì„± ê°€ì¤‘ì¹˜ (ìµœê·¼ ë…¸ì¶œì´ ë” ì˜í–¥ë ¥ ìžˆìŒ)
        if self.last_exposure and self.first_exposure:
            time_span = self.last_exposure - self.first_exposure
            if time_span > 0:
                # ìµœê·¼ ë…¸ì¶œë“¤ì˜ ë¹„ì¤‘
                recent_weight = sum(self.intensity_history[-10:]) / max(1, len(self.intensity_history[-10:]))
                old_weight = sum(self.intensity_history[:10]) / max(1, len(self.intensity_history[:10])) if len(self.intensity_history) > 10 else recent_weight
                if old_weight > 0:
                    self.recency_weight = recent_weight / old_weight
                else:
                    self.recency_weight = 1.0
    
    def get_observation_data(self) -> Dict:
        """
        ê´€ì°°ìš© ë°ì´í„° ë°˜í™˜
        
        ì´ ë°ì´í„°ë¥¼ ê°€ì§€ê³  "ì„±ê²©"ì„ ê´€ì°°/ì‹¤í—˜/ì¡°ì •í•  ìˆ˜ ìžˆìŒ
        """
        return {
            'key': self.key,
            
            # ê¸°ë³¸ ì¶•ì  ë°ì´í„°
            'exposure_count': self.exposure_count,
            'total_intensity': self.total_intensity,
            'total_valence': self.total_valence,
            'first_exposure': self.first_exposure,
            'last_exposure': self.last_exposure,
            
            # íŒŒìƒ ì§€í‘œ (ì„±ê²© í˜•ì„± ìž¬ë£Œ)
            'avg_intensity': self.avg_intensity,
            'avg_valence': self.avg_valence,        # -1~+1: ì‹«ì–´í•¨~ì¢‹ì•„í•¨
            'consistency': self.consistency,         # 0~1: ë°˜ì‘ ì¼ê´€ì„±
            'recency_weight': self.recency_weight,   # ìµœê·¼ ê´€ì‹¬ë„ ë³€í™”
            
            # í•´ì„ ížŒíŠ¸ (ì‹¤í—˜ìžê°€ ì°¸ê³ )
            'interpretation_hints': {
                'interest_level': self.avg_intensity,  # ê´€ì‹¬ë„
                'preference': self.avg_valence,        # ì„ í˜¸ë„
                'stability': self.consistency,         # ì•ˆì •ì„±
                'trend': 'increasing' if self.recency_weight > 1.2 else 
                        'decreasing' if self.recency_weight < 0.8 else 'stable'
            }
        }
    
    def to_dict(self) -> Dict:
        return {
            'key': self.key,
            'total_intensity': self.total_intensity,
            'total_valence': self.total_valence,
            'exposure_count': self.exposure_count,
            'first_exposure': self.first_exposure,
            'last_exposure': self.last_exposure,
            'intensity_history': self.intensity_history,
            'valence_history': self.valence_history,
            'interval_history': self.interval_history,
            'avg_intensity': self.avg_intensity,
            'avg_valence': self.avg_valence,
            'consistency': self.consistency,
            'recency_weight': self.recency_weight,
        }
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'AccumulatedTrace':
        trace = cls(data['key'])
        trace.total_intensity = data.get('total_intensity', 0.0)
        trace.total_valence = data.get('total_valence', 0.0)
        trace.exposure_count = data.get('exposure_count', 0)
        trace.first_exposure = data.get('first_exposure')
        trace.last_exposure = data.get('last_exposure')
        trace.intensity_history = data.get('intensity_history', [])
        trace.valence_history = data.get('valence_history', [])
        trace.interval_history = data.get('interval_history', [])
        trace.avg_intensity = data.get('avg_intensity', 0.0)
        trace.avg_valence = data.get('avg_valence', 0.0)
        trace.consistency = data.get('consistency', 0.0)
        trace.recency_weight = data.get('recency_weight', 0.0)
        return trace


class StimulusAccumulator:
    """
    ìžê·¹ ì¶•ì ê¸°
    
    ê¸°ì–µì´ ìŒ“ì´ëŠ” ê³¼ì • = ì„±ê²©ì´ í˜•ì„±ë˜ëŠ” ê³¼ì •
    ì˜ "êµ¬ì¡°"ë¥¼ ì œê³µí•¨.
    
    ì„±ê²© ìžì²´ëŠ” êµ¬í˜„í•˜ì§€ ì•ŠìŒ (ê´€ì°°/ì‹¤í—˜ ì˜ì—­)
    ì„±ê²©ì´ í˜•ì„±ë  ìˆ˜ ìžˆëŠ” ì¸í”„ë¼ë¥¼ ì œê³µ.
    """
    
    VERSION = "1.0.0"
    
    def __init__(self, name: str = "default"):
        self.name = name
        self.created_at = time.time()
        
        # === Storage ===
        # ëª¨ë“  ìžê·¹ ë¡œê·¸ (ì‹œê°„ìˆœ)
        self._stimulus_log: List[Stimulus] = []
        
        # ì¶•ì ëœ í”ì  (key -> AccumulatedTrace)
        self._traces: Dict[str, AccumulatedTrace] = {}
        
        # ë§¥ë½ë³„ ì¸ë±ìŠ¤
        self._context_index: Dict[str, List[int]] = defaultdict(list)
        
        # ì„¤ì •
        self.log_limit = 10000  # ìžê·¹ ë¡œê·¸ ìµœëŒ€ í¬ê¸°
    
    # =========================================================
    # ðŸ“¥ INPUT: ìžê·¹ ìˆ˜ì‹ 
    # =========================================================
    
    def receive(self,
                content: str,
                intensity: float = 0.5,
                valence: float = 0.0,
                context: str = None) -> Stimulus:
        """
        ìžê·¹ ìˆ˜ì‹  ë° ì¶•ì 
        
        Args:
            content: ìžê·¹ ë‚´ìš© (í‚¤ì›Œë“œ, ì£¼ì œ ë“±)
            intensity: ê°•ë„ (0.0~1.0)
            valence: ê°ì •ê°€ (-1.0=ë¶€ì •, +1.0=ê¸ì •)
            context: ë§¥ë½
        
        Returns:
            ìƒì„±ëœ Stimulus ê°ì²´
        
        ì˜ˆì‹œ:
            # ê³ ì–‘ì´ë¥¼ ë³´ê³  ê¸°ë¶„ ì¢‹ìŒ
            acc.receive("ê³ ì–‘ì´", intensity=0.7, valence=0.8)
            
            # ê°œí•œí…Œ ë¬¼ë¦¼ (ê°•í•œ ë¶€ì • ìžê·¹)
            acc.receive("ê°œ", intensity=0.95, valence=-0.9)
        """
        stimulus = Stimulus(content, intensity, valence, context)
        
        # ë¡œê·¸ì— ì¶”ê°€
        log_idx = len(self._stimulus_log)
        self._stimulus_log.append(stimulus)
        
        # ìš©ëŸ‰ ê´€ë¦¬
        if len(self._stimulus_log) > self.log_limit:
            self._stimulus_log.pop(0)
        
        # ë§¥ë½ ì¸ë±ìŠ¤
        if context:
            self._context_index[context].append(log_idx)
        
        # í”ì ì— ì¶•ì 
        if content not in self._traces:
            self._traces[content] = AccumulatedTrace(content)
        
        self._traces[content].accumulate(stimulus)
        
        return stimulus
    
    def receive_batch(self, stimuli: List[Dict]):
        """
        ì—¬ëŸ¬ ìžê·¹ ì¼ê´„ ìˆ˜ì‹ 
        
        Args:
            stimuli: [{'content': ..., 'intensity': ..., 'valence': ...}, ...]
        """
        for s in stimuli:
            self.receive(
                content=s.get('content', ''),
                intensity=s.get('intensity', 0.5),
                valence=s.get('valence', 0.0),
                context=s.get('context')
            )
    
    # =========================================================
    # ðŸ“Š OBSERVE: íŒ¨í„´ ê´€ì°° (ì‹¤í—˜ìžìš©)
    # =========================================================
    
    def get_trace(self, key: str) -> Optional[Dict]:
        """
        íŠ¹ì • ì£¼ì œì˜ ì¶•ì  í”ì  ì¡°íšŒ
        
        Returns:
            ê´€ì°°ìš© ë°ì´í„° (ì„±ê²© í˜•ì„± ìž¬ë£Œ)
        """
        if key not in self._traces:
            return None
        return self._traces[key].get_observation_data()
    
    def get_all_traces(self) -> Dict[str, Dict]:
        """ëª¨ë“  í”ì  ì¡°íšŒ"""
        return {
            key: trace.get_observation_data()
            for key, trace in self._traces.items()
        }
    
    def get_patterns(self, 
                     min_exposure: int = 2,
                     sort_by: str = 'total_intensity') -> List[Dict]:
        """
        í˜•ì„±ëœ íŒ¨í„´ë“¤ ì¡°íšŒ
        
        Args:
            min_exposure: ìµœì†Œ ë…¸ì¶œ íšŸìˆ˜ í•„í„°
            sort_by: ì •ë ¬ ê¸°ì¤€ 
                    ('total_intensity', 'avg_valence', 'exposure_count', 'consistency')
        
        Returns:
            íŒ¨í„´ ë¦¬ìŠ¤íŠ¸ (ì •ë ¬ë¨)
        
        ì´ ë°ì´í„°ë¡œ "ì„±ê²©ì´ ì–´ë–»ê²Œ í˜•ì„±ë˜ê³  ìžˆëŠ”ì§€" ê´€ì°°
        """
        patterns = []
        
        for trace in self._traces.values():
            if trace.exposure_count >= min_exposure:
                data = trace.get_observation_data()
                patterns.append(data)
        
        # ì •ë ¬
        if sort_by in ['total_intensity', 'avg_valence', 'exposure_count', 'consistency']:
            patterns.sort(key=lambda x: abs(x.get(sort_by, 0)), reverse=True)
        
        return patterns
    
    def get_top_interests(self, n: int = 10) -> List[Dict]:
        """
        ê°€ìž¥ ê´€ì‹¬ ìžˆëŠ” ì£¼ì œë“¤ (ë†’ì€ intensity)
        
        â†’ "ì´ AIê°€ ë¬´ì—‡ì— ê´€ì‹¬ ìžˆëŠ”ì§€" ê´€ì°°
        """
        return self.get_patterns(min_exposure=1, sort_by='total_intensity')[:n]
    
    def get_preferences(self, n: int = 10) -> Tuple[List[Dict], List[Dict]]:
        """
        ì„ í˜¸/ë¹„ì„ í˜¸ ì£¼ì œë“¤ (valence ê¸°ì¤€)
        
        Returns:
            (ì¢‹ì•„í•˜ëŠ” ê²ƒë“¤, ì‹«ì–´í•˜ëŠ” ê²ƒë“¤)
        
        â†’ "ì´ AIê°€ ë¬´ì—‡ì„ ì¢‹ì•„í•˜ê³  ì‹«ì–´í•˜ëŠ”ì§€" ê´€ì°°
        """
        patterns = self.get_patterns(min_exposure=2)
        
        likes = sorted([p for p in patterns if p['avg_valence'] > 0.2],
                      key=lambda x: x['avg_valence'], reverse=True)[:n]
        
        dislikes = sorted([p for p in patterns if p['avg_valence'] < -0.2],
                         key=lambda x: x['avg_valence'])[:n]
        
        return likes, dislikes
    
    def get_stable_traits(self, consistency_threshold: float = 0.7) -> List[Dict]:
        """
        ì•ˆì •ì ì¸ íŠ¹ì„±ë“¤ (ë†’ì€ consistency)
        
        â†’ "êµ³ì–´ì§„ ì„±ê²©ì  íŠ¹ì„±" ê´€ì°°
        """
        patterns = self.get_patterns(min_exposure=5)
        return [p for p in patterns if p['consistency'] >= consistency_threshold]
    
    # =========================================================
    # ðŸ”§ ADJUST: ì‹¤í—˜/ì¡°ì •ìš© í•¨ìˆ˜
    # =========================================================
    
    def adjust_trace(self, 
                     key: str, 
                     intensity_delta: float = 0.0,
                     valence_delta: float = 0.0):
        """
        í”ì  ìˆ˜ë™ ì¡°ì • (ì‹¤í—˜ìš©)
        
        Args:
            key: ì¡°ì •í•  ì£¼ì œ
            intensity_delta: ê°•ë„ ë³€í™”ëŸ‰
            valence_delta: ê°ì •ê°€ ë³€í™”ëŸ‰
        
        ì‹¤í—˜ìžê°€ íŠ¹ì • ì¡°ê±´ì„ ë§Œë“¤ì–´ ê´€ì°°í•  ë•Œ ì‚¬ìš©
        """
        if key not in self._traces:
            return
        
        trace = self._traces[key]
        trace.total_intensity += intensity_delta
        trace.total_valence += valence_delta * abs(intensity_delta) if intensity_delta else valence_delta
        trace._update_derived_metrics()
    
    def inject_experience(self,
                          key: str,
                          intensity: float,
                          valence: float,
                          count: int = 1):
        """
        ê²½í—˜ ì£¼ìž… (ì‹¤í—˜ìš©)
        
        íŠ¹ì • ê²½í—˜ì„ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µí•œ ê²ƒì²˜ëŸ¼ ì£¼ìž…
        ì„±ê²© í˜•ì„± ê³¼ì •ì„ ê°€ì†í•˜ê±°ë‚˜ íŠ¹ì • ì¡°ê±´ ë§Œë“¤ê¸°
        """
        for _ in range(count):
            self.receive(key, intensity=intensity, valence=valence)
    
    def reset_trace(self, key: str):
        """íŠ¹ì • í”ì  ì´ˆê¸°í™” (ì‹¤í—˜ìš©)"""
        if key in self._traces:
            del self._traces[key]
    
    def decay_all(self, rate: float = 0.01):
        """
        ì „ì²´ í”ì  ê°ì‡  (ì‹œê°„ ê²½ê³¼ ì‹œë®¬ë ˆì´ì…˜)
        
        ì˜¤ëž˜ëœ ìžê·¹ì˜ ì˜í–¥ë ¥ì´ ì¤„ì–´ë“œëŠ” ê²ƒì„ ì‹œë®¬ë ˆì´ì…˜
        í•˜ì§€ë§Œ ì™„ì „ížˆ ì‚¬ë¼ì§€ì§€ëŠ” ì•ŠìŒ (ì¸ê°„ì²˜ëŸ¼)
        """
        for trace in self._traces.values():
            # intensity ê°ì‡  (ìµœì†Œê°’ ìœ ì§€)
            decay_amount = trace.total_intensity * rate
            trace.total_intensity = max(
                trace.total_intensity * 0.1,  # ìµœì†Œ 10% ìœ ì§€
                trace.total_intensity - decay_amount
            )
            
            # valenceëŠ” ê°ì‡ í•˜ì§€ ì•ŠìŒ (ì¢‹ì•„í•¨/ì‹«ì–´í•¨ì€ ìž˜ ì•ˆ ë³€í•¨)
            
            trace._update_derived_metrics()
    
    # =========================================================
    # ðŸ’¾ PERSISTENCE: ì €ìž¥/ë¡œë“œ
    # =========================================================
    
    def save(self, path: str = None) -> str:
        """ì €ìž¥"""
        if path is None:
            save_dir = Path.home() / ".babyhippo" / "accumulator"
            save_dir.mkdir(parents=True, exist_ok=True)
            path = str(save_dir / f"{self.name}.json")
        
        data = {
            'version': self.VERSION,
            'name': self.name,
            'created_at': self.created_at,
            'saved_at': time.time(),
            
            'stimulus_log': [s.to_dict() for s in self._stimulus_log],
            'traces': {k: v.to_dict() for k, v in self._traces.items()},
            'context_index': dict(self._context_index),
        }
        
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        return path
    
    def load(self, path: str = None):
        """ë¡œë“œ"""
        if path is None:
            path = str(Path.home() / ".babyhippo" / "accumulator" / f"{self.name}.json")
        
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        self.name = data.get('name', self.name)
        self.created_at = data.get('created_at', time.time())
        
        self._stimulus_log = [Stimulus.from_dict(s) for s in data.get('stimulus_log', [])]
        self._traces = {k: AccumulatedTrace.from_dict(v) for k, v in data.get('traces', {}).items()}
        self._context_index = defaultdict(list, data.get('context_index', {}))
    
    # =========================================================
    # ðŸ“ˆ STATS
    # =========================================================
    
    def get_stats(self) -> Dict:
        """í†µê³„"""
        patterns = self.get_patterns(min_exposure=1)
        
        return {
            'version': self.VERSION,
            'name': self.name,
            'total_stimuli': len(self._stimulus_log),
            'unique_topics': len(self._traces),
            'contexts': list(self._context_index.keys()),
            
            # ì „ì²´ ê²½í–¥ (ì„±ê²© í˜•ì„± ë°©í–¥)
            'overall_tendency': {
                'avg_interest': sum(p['avg_intensity'] for p in patterns) / max(1, len(patterns)),
                'avg_sentiment': sum(p['avg_valence'] for p in patterns) / max(1, len(patterns)),
                'most_exposed': patterns[0]['key'] if patterns else None,
            }
        }
    
    def __repr__(self):
        return f"StimulusAccumulator('{self.name}', {len(self._traces)} traces)"
    
    def __len__(self):
        return len(self._stimulus_log)


# =========================================================
# ðŸ§ª TEST
# =========================================================

if __name__ == "__main__":
    print("=" * 60)
    print("ðŸ§  Stimulus Accumulator Test")
    print("   (ì„±ê²© í˜•ì„± ê¸°ë°˜ êµ¬ì¡°)")
    print("=" * 60)
    
    acc = StimulusAccumulator("test_personality")
    
    # === ìžê·¹ ìˆ˜ì‹  ì‹œë®¬ë ˆì´ì…˜ ===
    print("\nðŸ“¥ Receiving stimuli...")
    
    # ê³ ì–‘ì´ì— ëŒ€í•œ ë°˜ë³µì  ê¸ì • ê²½í—˜
    for i in range(5):
        acc.receive("ê³ ì–‘ì´", intensity=0.7 + i*0.05, valence=0.8)
    
    # ê°œì— ëŒ€í•œ ê°•í•œ ë¶€ì • ê²½í—˜ (í•œë²ˆ ë¬¼ë¦¼)
    acc.receive("ê°œ", intensity=0.95, valence=-0.9)
    # ì´í›„ ì¡°ì‹¬ìŠ¤ëŸ¬ìš´ ë¶€ì • ê²½í—˜ë“¤
    for _ in range(3):
        acc.receive("ê°œ", intensity=0.3, valence=-0.3)
    
    # í”„ë¡œê·¸ëž˜ë°ì— ëŒ€í•œ ì¤‘ë¦½ì ì´ì§€ë§Œ ê¾¸ì¤€í•œ ë…¸ì¶œ
    for _ in range(10):
        acc.receive("í”„ë¡œê·¸ëž˜ë°", intensity=0.6, valence=0.2)
    
    # ìŒì•…ì— ëŒ€í•œ ê°€ë” ê¸ì • ê²½í—˜
    acc.receive("ìŒì•…", intensity=0.8, valence=0.9)
    acc.receive("ìŒì•…", intensity=0.5, valence=0.7)
    
    # === íŒ¨í„´ ê´€ì°° ===
    print("\nðŸ“Š Observing patterns (ì„±ê²© í˜•ì„± ìž¬ë£Œ):")
    print("-" * 50)
    
    patterns = acc.get_patterns()
    for p in patterns:
        hints = p['interpretation_hints']
        print(f"\n  [{p['key']}]")
        print(f"    ë…¸ì¶œ íšŸìˆ˜: {p['exposure_count']}")
        print(f"    ê´€ì‹¬ë„: {hints['interest_level']:.2f}")
        print(f"    ì„ í˜¸ë„: {hints['preference']:.2f} ({'ì¢‹ì•„í•¨' if hints['preference'] > 0.3 else 'ì‹«ì–´í•¨' if hints['preference'] < -0.3 else 'ì¤‘ë¦½'})")
        print(f"    ì•ˆì •ì„±: {hints['stability']:.2f}")
        print(f"    ì¶”ì„¸: {hints['trend']}")
    
    # === ì„ í˜¸/ë¹„ì„ í˜¸ ===
    print("\n" + "-" * 50)
    print("â¤ï¸  ì¢‹ì•„í•˜ëŠ” ê²ƒë“¤:")
    likes, dislikes = acc.get_preferences()
    for p in likes:
        print(f"    â€¢ {p['key']} (ì„ í˜¸ë„: {p['avg_valence']:.2f})")
    
    print("\nðŸ’” ì‹«ì–´í•˜ëŠ” ê²ƒë“¤:")
    for p in dislikes:
        print(f"    â€¢ {p['key']} (ì„ í˜¸ë„: {p['avg_valence']:.2f})")
    
    # === í†µê³„ ===
    print("\n" + "-" * 50)
    print("ðŸ“ˆ Stats:")
    stats = acc.get_stats()
    for k, v in stats.items():
        print(f"    {k}: {v}")
    
    print("\n" + "=" * 60)
    print("âœ… ì´ ë°ì´í„°ë¥¼ ê°€ì§€ê³  'ì„±ê²© í˜•ì„±'ì„ ê´€ì°°/ì‹¤í—˜/ì¡°ì • ê°€ëŠ¥")
    print("âœ… ì„±ê²© ìžì²´ëŠ” êµ¬í˜„í•˜ì§€ ì•ŠìŒ - emergenceë¥¼ ê´€ì°°í•˜ëŠ” ê²ƒ")
    print("=" * 60)

