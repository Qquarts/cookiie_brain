"""
BrainLLM: í•´ë§ˆ ì¤‘ì‹¬ LLM í†µí•© ì‹œìŠ¤í…œ

ğŸ§  ì² í•™:
    LLMì— ê¸°ì–µ ë¶™ì´ê¸° âŒ (ê±°ê¾¸ë¡œ)
    í•´ë§ˆì— LLM ë¶™ì´ê¸° â­• (ìƒë¬¼í•™ì ìœ¼ë¡œ ë§ìŒ)
    
    ê¸°ì–µì´ ë¨¼ì € â†’ ì–¸ì–´ëŠ” ë‚˜ì¤‘
    í•´ë§ˆê°€ ì¤‘ì‹¬ â†’ LLMì€ ì–¸ì–´ í”¼ì§ˆ ëª¨ë“ˆ

êµ¬ì¡°:
    Hippocampus (í•´ë§ˆ) = ê¸°ì–µì˜ ì¤‘ì‹¬
         â†“ ê³µê³ í™” (consolidation)
    nanoGPT (ì–¸ì–´ í”¼ì§ˆ) = ì–¸ì–´ ì²˜ë¦¬
    
    ì‹œê°„ì´ ì§€ë‚˜ë©´ í•´ë§ˆ ê¸°ì–µ â†’ LLMìœ¼ë¡œ ì „ì´
    ì•„ê¸°ê°€ ìë¼ë©´ì„œ ì–¸ì–´ë¥¼ ë°°ìš°ëŠ” ê²ƒì²˜ëŸ¼

Author: GNJz (Qquarts)
Version: 1.0
"""

import sys
import os
from pathlib import Path
from typing import Dict, List, Optional, Any
import json
import time

# nanoGPT ê²½ë¡œ ì¶”ê°€
NANOGPT_PATH = Path(__file__).parent.parent.parent / "nanoGPT"
sys.path.insert(0, str(NANOGPT_PATH))

# ëª¨ë“ˆ ì„í¬íŠ¸ (ìƒˆ êµ¬ì¡°)
from ..memory import HippoMemory, PanoramaMemory, MemoryRank
from ..utils import StimulusAccumulator


class HippoToLLM:
    """
    í•´ë§ˆ â†’ LLM ì „ì´ ë©”ì»¤ë‹ˆì¦˜
    
    ê³µê³ í™”ëœ ê¸°ì–µì„ LLM í•™ìŠµ ë°ì´í„°ë¡œ ë³€í™˜
    ì‹¤ì œ ë‡Œì—ì„œ í•´ë§ˆâ†’ëŒ€ë‡Œí”¼ì§ˆ ì „ì´ì²˜ëŸ¼
    """
    
    def __init__(self, hippocampus: HippoMemory, panorama: PanoramaMemory = None):
        self.hippo = hippocampus
        self.panorama = panorama or PanoramaMemory("brain_llm")
        self.accumulator = StimulusAccumulator("brain_llm")
        
        # ì „ì´ ì„ê³„ê°’
        self.consolidation_threshold = 0.7  # ì´ ì´ìƒ ê³µê³ í™”ë˜ë©´ ì „ì´
        
        # ì „ì´ëœ ê¸°ì–µ ê¸°ë¡
        self.transferred_memories: List[str] = []
        
        # í•™ìŠµ ë°ì´í„° ì €ì¥
        self.training_data: List[Dict] = []
    
    def collect_consolidated_memories(self) -> List[Dict]:
        """
        ê³µê³ í™”ëœ ê¸°ì–µ ìˆ˜ì§‘ (ì „ì´ ëŒ€ìƒ)
        
        consolidation_level > thresholdì¸ ê¸°ì–µë“¤
        """
        consolidated = []
        
        for word_id, word_info in self.hippo.words.items():
            # ì´ë¯¸ ì „ì´ëœ ê±´ ìŠ¤í‚µ
            if word_id in self.transferred_memories:
                continue
            
            # ì‹œëƒ…ìŠ¤ì˜ í‰ê·  ê³µê³ í™” ìˆ˜ì¤€
            synapses = word_info.get('synapses_dg_ca3', [])
            if not synapses:
                continue
            
            avg_consolidation = sum(
                syn.consolidation_level for syn in synapses
            ) / len(synapses)
            
            if avg_consolidation >= self.consolidation_threshold:
                # ì „ì´ ëŒ€ìƒ
                importance = self.hippo.memory_ranker.get_score(word_id, default=0.5)
                
                consolidated.append({
                    'word_id': word_id,
                    'consolidation': avg_consolidation,
                    'importance': importance,
                    'context': self.hippo.contexts.get(word_id),
                    'frequency': self.hippo.word_frequencies.get(word_id, 1),
                })
        
        return consolidated
    
    def memory_to_training_text(self, memory: Dict) -> str:
        """
        ê¸°ì–µì„ í•™ìŠµ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        
        Args:
            memory: ê³µê³ í™”ëœ ê¸°ì–µ ì •ë³´
            
        Returns:
            í•™ìŠµìš© í…ìŠ¤íŠ¸
        """
        word_id = memory['word_id']
        context = memory.get('context', '')
        importance = memory.get('importance', 0.5)
        
        # ê¸°ë³¸ í…ìŠ¤íŠ¸
        text = word_id
        
        # ë§¥ë½ ì¶”ê°€
        if context:
            text = f"{context}: {text}"
        
        # Panoramaì—ì„œ ê´€ë ¨ ê¸°ì–µ ì°¾ê¸°
        if self.panorama:
            related = self.panorama.recall(word_id, top_n=3, include_deep=True)
            for r in related:
                content = r.get('content', '')
                if content and content != word_id:
                    text += f" {content}"
        
        return text
    
    def prepare_training_data(self) -> List[str]:
        """
        LLM í•™ìŠµ ë°ì´í„° ì¤€ë¹„
        
        Returns:
            í•™ìŠµìš© í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        consolidated = self.collect_consolidated_memories()
        
        training_texts = []
        for mem in consolidated:
            text = self.memory_to_training_text(mem)
            training_texts.append(text)
            
            # ì „ì´ ê¸°ë¡
            self.transferred_memories.append(mem['word_id'])
            self.training_data.append({
                'text': text,
                'memory': mem,
                'transferred_at': time.time()
            })
        
        return training_texts
    
    def export_for_nanogpt(self, output_path: str = None) -> str:
        """
        nanoGPT í•™ìŠµìš© ë°ì´í„° íŒŒì¼ ìƒì„±
        
        Args:
            output_path: ì¶œë ¥ ê²½ë¡œ (ê¸°ë³¸: data/hippo/train.txt)
            
        Returns:
            ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ
        """
        if output_path is None:
            output_dir = NANOGPT_PATH / "data" / "hippo"
            output_dir.mkdir(parents=True, exist_ok=True)
            output_path = str(output_dir / "train.txt")
        
        # í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
        training_texts = self.prepare_training_data()
        
        # íŒŒì¼ ì‘ì„±
        with open(output_path, 'w', encoding='utf-8') as f:
            for text in training_texts:
                f.write(text + '\n')
        
        return output_path
    
    def get_transfer_stats(self) -> Dict:
        """ì „ì´ í†µê³„"""
        return {
            'total_memories': len(self.hippo.words),
            'transferred': len(self.transferred_memories),
            'pending': len(self.hippo.words) - len(self.transferred_memories),
            'training_samples': len(self.training_data),
            'threshold': self.consolidation_threshold,
        }


class BrainLLM:
    """
    í•´ë§ˆ ì¤‘ì‹¬ LLM ì‹œìŠ¤í…œ
    
    í•´ë§ˆ(ê¸°ì–µ) + nanoGPT(ì–¸ì–´) í†µí•©
    ê¸°ì–µì„ ì°¸ì¡°í•˜ë©´ì„œ ì–¸ì–´ ìƒì„±
    """
    
    def __init__(self, 
                 hippocampus: HippoMemory = None,
                 model_path: str = None,
                 device: str = 'auto'):
        """
        Args:
            hippocampus: HippoMemory ì¸ìŠ¤í„´ìŠ¤ (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)
            model_path: í•™ìŠµëœ nanoGPT ëª¨ë¸ ê²½ë¡œ
            device: 'cpu' or 'cuda'
        """
        # í•´ë§ˆ (ê¸°ì–µ ì¤‘ì‹¬)
        self.hippo = hippocampus or HippoMemory()
        self.panorama = PanoramaMemory("brain_llm")
        self.accumulator = StimulusAccumulator("brain_llm")
        
        # ì „ì´ ë©”ì»¤ë‹ˆì¦˜
        self.transfer = HippoToLLM(self.hippo, self.panorama)
        
        # ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ
        # ğŸª ì €ì „ë ¥ ëª¨ë“œ: ê¸°ë³¸ì ìœ¼ë¡œ CPUë§Œ ì‚¬ìš© (ë¼ì¦ˆë² ë¦¬íŒŒì´/ì—£ì§€ ë””ë°”ì´ìŠ¤ ìµœì í™”)
        if device == 'auto':
            # ì €ì „ë ¥ ëª¨ë“œ: GPU ì‚¬ìš© ì•ˆ í•¨ (ë°œì—´/ì „ë ¥ ì ˆì•½)
            self.device = 'cpu'
            print("ğŸ’» CPU ì‚¬ìš© (ì €ì „ë ¥ ëª¨ë“œ)")
            # GPU ì‚¬ìš©ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì•„ë˜ ì£¼ì„ í•´ì œ:
            # import torch
            # if torch.backends.mps.is_available():
            #     self.device = 'mps'  # Apple Silicon GPU
            #     print("ğŸš€ Apple GPU (MPS) ì‚¬ìš©")
            # elif torch.cuda.is_available():
            #     self.device = 'cuda'  # NVIDIA GPU
            #     print("ğŸš€ NVIDIA GPU (CUDA) ì‚¬ìš©")
            # else:
            #     self.device = 'cpu'
            #     print("ğŸ’» CPU ì‚¬ìš©")
        else:
            self.device = device
        
        # nanoGPT ëª¨ë¸
        self.model = None
        self.model_path = model_path
        
        # ë¬¸ì ì¸ì½”ë”© (char-level)
        self.stoi = {}
        self.itos = {}
        
        # ì„¤ì •
        self.config = {
            'max_tokens': 100,
            'temperature': 0.8,
            'top_k': 40,
        }
        
        # ëª¨ë¸ ë¡œë“œ
        # ğŸª ì €ì „ë ¥ ëª¨ë“œ: ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë¸ ë¡œë“œ ì•ˆ í•¨ (ë¼ì¦ˆë² ë¦¬íŒŒì´/ì—£ì§€ ë””ë°”ì´ìŠ¤ ìµœì í™”)
        # ëª¨ë¸ì´ í•„ìš”í•˜ë©´ ëª…ì‹œì ìœ¼ë¡œ load_model() í˜¸ì¶œ
        # if model_path and os.path.exists(model_path):
        #     self.load_model(model_path)
    
    def load_model(self, path: str):
        """í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ"""
        try:
            import torch
            sys.path.insert(0, str(NANOGPT_PATH))
            from model import GPT, GPTConfig
            import pickle
            
            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
            checkpoint = torch.load(path, map_location=self.device, weights_only=False)
            
            # ëª¨ë¸ ìƒì„±
            config = GPTConfig(**checkpoint['model_args'])
            self.model = GPT(config)
            
            # state dict ì •ë¦¬
            state_dict = checkpoint['model']
            unwanted_prefix = '_orig_mod.'
            for k, v in list(state_dict.items()):
                if k.startswith(unwanted_prefix):
                    state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)
            
            self.model.load_state_dict(state_dict)
            self.model.to(self.device)
            self.model.eval()
            
            # ë©”íƒ€ ì •ë³´ ë¡œë“œ (ë¬¸ì ì¸ì½”ë”©)
            meta_path = NANOGPT_PATH / "data" / "hippo" / "meta.pkl"
            if meta_path.exists():
                with open(meta_path, 'rb') as f:
                    meta = pickle.load(f)
                self.stoi = meta['stoi']
                self.itos = meta['itos']
            
            print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {path}")
            print(f"   íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in self.model.parameters()):,}")
            
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            self.model = None
    
    def learn(self, text: str, context: str = None, importance: float = 0.5):
        """
        ìƒˆë¡œìš´ ì •ë³´ í•™ìŠµ (í•´ë§ˆì— ì €ì¥)
        
        ğŸª v1.0: í‚¤ì›Œë“œ ì¶”ì¶œí•˜ì—¬ ì €ì¥
        
        Args:
            text: í•™ìŠµí•  í…ìŠ¤íŠ¸
            context: ë§¥ë½
            importance: ì¤‘ìš”ë„
        """
        # ğŸª v1.0: í‚¤ì›Œë“œ ì¶”ì¶œ (ì²« ë‹¨ì–´ ë˜ëŠ” ì£¼ìš” ë‹¨ì–´)
        # ì˜ˆ: "AëŠ” ì•ŒíŒŒë²³ ì²« ê¸€ìì…ë‹ˆë‹¤." â†’ "A"ì™€ ì „ì²´ ë¬¸ì¥ ëª¨ë‘ ì €ì¥
        keywords = []
        words = text.split()
        if words:
            # ì²« ë‹¨ì–´ê°€ í‚¤ì›Œë“œì¼ ê°€ëŠ¥ì„± ë†’ìŒ
            first_word = words[0].strip('ëŠ”ì€ì´ê°€ì„ë¥¼ì˜ì—ì™€ê³¼')
            if first_word:
                keywords.append(first_word)
        
        # í•´ë§ˆì— ì €ì¥ (í‚¤ì›Œë“œì™€ ì „ì²´ ë¬¸ì¥ ëª¨ë‘)
        for keyword in keywords:
            self.hippo.learn(keyword, context=context)
        # ì „ì²´ ë¬¸ì¥ë„ ì €ì¥
        self.hippo.learn(text, context=context)
        
        # Panoramaì— ì €ì¥
        self.panorama.store(
            content=text,
            context=context,
            importance=importance
        )
        
        # ìê·¹ ì¶•ì 
        self.accumulator.receive(
            content=text,
            intensity=importance,
            valence=0.0,
            context=context
        )
    
    def recall(self, query: str, top_n: int = 5) -> List[Dict]:
        """
        ê¸°ì–µ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ì–´
            top_n: ë°˜í™˜ ê°œìˆ˜
            
        Returns:
            ê´€ë ¨ ê¸°ì–µë“¤
        """
        results = []
        
        # í•´ë§ˆì—ì„œ ê²€ìƒ‰
        hippo_results = self.hippo.recall(query, top_n=top_n)
        if hippo_results:
            if isinstance(hippo_results, str):
                # ğŸª v1.0: ë¬¸ìì—´ì´ë©´ ë°”ë¡œ ì‚¬ìš© (ì´ë¯¸ ì›ë³¸ í…ìŠ¤íŠ¸)
                results.append({'source': 'hippo', 'content': hippo_results, 'score': 0.8})
            else:
                # ğŸª v1.0: (word_text, score) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
                for word_text, score in hippo_results:
                    results.append({
                        'source': 'hippo',
                        'content': word_text,
                        'score': score
                    })
        
        # Panoramaì—ì„œ ê²€ìƒ‰
        panorama_results = self.panorama.recall(query, top_n=top_n)
        for r in panorama_results:
            results.append({
                'source': 'panorama',
                'content': r.get('content'),
                'score': r.get('recall_score', 0.5)
            })
        
        # ì ìˆ˜ë¡œ ì •ë ¬
        results.sort(key=lambda x: x.get('score', 0), reverse=True)
        
        return results[:top_n]
    
    def generate(self, prompt: str, use_memory: bool = True) -> str:
        """
        í…ìŠ¤íŠ¸ ìƒì„± (í•´ë§ˆ ì°¸ì¡°)
        
        Args:
            prompt: í”„ë¡¬í”„íŠ¸
            use_memory: ê¸°ì–µ ì°¸ì¡° ì—¬ë¶€
            
        Returns:
            ìƒì„±ëœ í…ìŠ¤íŠ¸
        """
        # ê¸°ì–µì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
        memory_context = ""
        if use_memory:
            memories = self.recall(prompt, top_n=3)
            if memories:
                memory_context = "[ê¸°ì–µ] " + " | ".join(
                    m.get('content', '') for m in memories if m.get('content')
                ) + "\n\n"
        
        # nanoGPTë¡œ ìƒì„±
        if self.model is not None:
            return self._generate_with_model(memory_context + prompt)
        else:
            # ëª¨ë¸ ì—†ìœ¼ë©´ ê¸°ì–µë§Œ ë°˜í™˜
            return memory_context + f"[ëª¨ë¸ ì—†ìŒ] í”„ë¡¬í”„íŠ¸: {prompt}"
    
    def _generate_with_model(self, prompt: str) -> str:
        """nanoGPT ëª¨ë¸ë¡œ ìƒì„± (ë¬¸ì ë‹¨ìœ„)"""
        try:
            import torch
            
            # ë¬¸ì ë‹¨ìœ„ ì¸ì½”ë”© (í•™ìŠµ ë°ì´í„°ì™€ ë™ì¼)
            if hasattr(self, 'stoi') and self.stoi:
                encode = lambda s: [self.stoi[c] for c in s if c in self.stoi]
                decode = lambda l: ''.join([self.itos[i] for i in l])
            else:
                return f"[ì˜¤ë¥˜] ì¸ì½”ë”© ë©”íƒ€ ì •ë³´ ì—†ìŒ"
            
            # ì¸ì½”ë”©
            tokens = encode(prompt)
            if not tokens:
                return f"[ì˜¤ë¥˜] ì¸ì½”ë”© ì‹¤íŒ¨: '{prompt}'"
            
            x = torch.tensor([tokens], dtype=torch.long, device=self.device)
            
            # ìƒì„±
            with torch.no_grad():
                y = self.model.generate(
                    x,
                    max_new_tokens=self.config['max_tokens'],
                    temperature=self.config['temperature'],
                    top_k=self.config['top_k']
                )
            
            # ë””ì½”ë”©
            generated = decode(y[0].tolist())
            
            return generated
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            return f"[ìƒì„± ì˜¤ë¥˜] {e}"
    
    def sleep(self, cycles: int = 10):
        """
        ìˆ˜ë©´ ê³µê³ í™”
        
        í•´ë§ˆ ê¸°ì–µ ê°•í™” + LLM ì „ì´ ì¤€ë¹„
        """
        # í•´ë§ˆ ê³µê³ í™”
        self.hippo.sleep(cycles=cycles)
        
        # ì „ì´ ê°€ëŠ¥í•œ ê¸°ì–µ í™•ì¸
        consolidated = self.transfer.collect_consolidated_memories()
        
        print(f"ğŸ’¤ ìˆ˜ë©´ ì™„ë£Œ: {cycles} ì‚¬ì´í´")
        print(f"   ì „ì´ ì¤€ë¹„ëœ ê¸°ì–µ: {len(consolidated)}ê°œ")
    
    def transfer_to_llm(self) -> str:
        """
        ê³µê³ í™”ëœ ê¸°ì–µì„ LLMìœ¼ë¡œ ì „ì´
        
        Returns:
            ìƒì„±ëœ í•™ìŠµ ë°ì´í„° ê²½ë¡œ
        """
        output_path = self.transfer.export_for_nanogpt()
        stats = self.transfer.get_transfer_stats()
        
        print(f"ğŸ§ â†’ğŸ“š ê¸°ì–µ ì „ì´ ì™„ë£Œ")
        print(f"   ì „ì´ëœ ê¸°ì–µ: {stats['transferred']}ê°œ")
        print(f"   í•™ìŠµ ë°ì´í„°: {output_path}")
        
        return output_path
    
    def get_stats(self) -> Dict:
        """í†µê³„"""
        return {
            'hippo': self.hippo.get_stats(),
            'panorama': self.panorama.get_stats(),
            'accumulator': self.accumulator.get_stats(),
            'transfer': self.transfer.get_transfer_stats(),
            'model_loaded': self.model is not None,
        }
    
    def __repr__(self):
        return f"BrainLLM(memories={len(self.hippo.words)}, model={'loaded' if self.model else 'none'})"


# =========================================================
# ğŸ§ª TEST
# =========================================================

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ§  BrainLLM Test - í•´ë§ˆ ì¤‘ì‹¬ LLM ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
    model_path = NANOGPT_PATH / "out-hippo" / "ckpt.pt"
    
    # ì‹œìŠ¤í…œ ìƒì„± (í•™ìŠµëœ ëª¨ë¸ í¬í•¨)
    print(f"\nğŸ”§ ì‹œìŠ¤í…œ ìƒì„± ì¤‘...")
    if model_path.exists():
        brain = BrainLLM(model_path=str(model_path))
    else:
        print(f"   âš ï¸ ëª¨ë¸ ì—†ìŒ: {model_path}")
        brain = BrainLLM()
    
    # í•™ìŠµ (í•´ë§ˆì— ì €ì¥)
    print("\nğŸ“ í•´ë§ˆì— ê¸°ì–µ ì €ì¥...")
    brain.learn("ì•ˆë…•í•˜ì„¸ìš” ì €ëŠ” ì¬ì§„ì…ë‹ˆë‹¤", context="ì†Œê°œ", importance=0.9)
    brain.learn("ê³ ì–‘ì´ë¥¼ ì¢‹ì•„í•©ë‹ˆë‹¤", context="ì„ í˜¸", importance=0.8)
    brain.learn("íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë°ì„ í•©ë‹ˆë‹¤", context="ê¸°ìˆ ", importance=0.7)
    brain.learn("ì„œìš¸ì— ì‚´ê³  ìˆìŠµë‹ˆë‹¤", context="ìœ„ì¹˜", importance=0.6)
    
    # ìˆ˜ë©´ (ê³µê³ í™”)
    print("\nğŸ’¤ ìˆ˜ë©´ ê³µê³ í™”...")
    for _ in range(3):
        brain.sleep(cycles=5)
    
    # ê¸°ì–µ ê²€ìƒ‰
    print("\nğŸ” ê¸°ì–µ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
    memories = brain.recall("ì¬ì§„")
    for m in memories[:3]:
        print(f"  [{m['source']}] {m['content']}")
    
    # ìƒì„± (ëª¨ë¸ ìˆìœ¼ë©´ LLM ì‚¬ìš©)
    print("\nâœ¨ í…ìŠ¤íŠ¸ ìƒì„± (í•´ë§ˆ + LLM):")
    
    prompts = [
        "ì•ˆë…•",
        "ê¸°ì–µì´ë€",
        "babyhippo",
    ]
    
    for prompt in prompts:
        print(f"\ní”„ë¡¬í”„íŠ¸: '{prompt}'")
        response = brain.generate(prompt)
        # ì²« 100ìë§Œ ì¶œë ¥
        print(f"  â†’ {response[:150]}...")
    
    # í†µê³„
    print("\nğŸ“Š í†µê³„:")
    stats = brain.get_stats()
    print(f"  í•´ë§ˆ ê¸°ì–µ: {stats['hippo']['words']}ê°œ")
    print(f"  LLM ëª¨ë¸: {'ë¡œë“œë¨ âœ…' if stats['model_loaded'] else 'ì—†ìŒ âŒ'}")
    
    print("\n" + "=" * 60)
    print("âœ… babyhippo í•´ë§ˆ ì¤‘ì‹¬ LLM ì‹œìŠ¤í…œ ì™„ì„±!")
    print("=" * 60)

